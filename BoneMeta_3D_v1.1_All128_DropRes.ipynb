{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JungOhLee/LiTS_example/blob/main/BoneMeta_3D_v1.1_All128_DropRes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkQzLHipM8Vv"
      },
      "source": [
        "#### Update for v1.1\n",
        "- v1.0 was valid to work\n",
        "- v1.1 added doPrediction for predict whole CT scan as in test setting. \n",
        "\n",
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tslyxsi7oeY8",
        "outputId": "31531d5c-9ab5-4988-bbb9-53cf17c3e61d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bQJBP8ynmpG",
        "outputId": "fa1a97f5-579b-452f-d372-4f5d68716bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting monai\n",
            "  Downloading monai-1.1.0-202212191849-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from monai) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.8/dist-packages (from monai) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8->monai) (4.4.0)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from nibabel) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.9.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.16.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.51.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install monai\n",
        "!pip install nibabel\n",
        "!pip install SimpleITK\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "244xQcIJg0RL"
      },
      "outputs": [],
      "source": [
        "MODEL_TO_LOAD = ''\n",
        "FN_LOSS = 0\n",
        "LEVELS = 5\n",
        "FILTER_NUM = 24\n",
        "\n",
        "TRAINING_NAME = f'3D_Unet_DropRes_lv{LEVELS}_All128'\n",
        "TB_PREFIX = 'bonemeta_fn_{}'.format(FN_LOSS) + '_{}'.format(TRAINING_NAME)\n",
        "\n",
        "PATCH_SIZE = 128\n",
        "\n",
        "# BATCH_SIZE = 120\n",
        "BATCH_SIZE = 2\n",
        "EPOCHS = 200\n",
        "\n",
        "BASE_DIR = '/gdrive/MyDrive/LiTS_sample'\n",
        "IMG_FOLDER_NAME = 'image_128'\n",
        "LABEL_FOLDER_NAME = 'mask_128'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sMMCsucbnmpH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr6YOqFNyy3v"
      },
      "source": [
        "# Set dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT6WRrXoI2fe",
        "outputId": "f5088eef-5cd7-4336-9440-9bc575bb0d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path './git_clone' already exists and is not an empty directory.\n",
            "mv: cannot stat './git_clone/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JungOhLee/LiTS_example.git ./git_clone\n",
        "!mv  -v ./git_clone/* ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhrhApsPz7Vw",
        "outputId": "a8db9319-b747-4a77-f8e3-75ca643bcc25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "augmentation.py\t\t\t       PrepareDataset.ipynb\n",
            "BoneMeta_3D_v1.1_All128_DropRes.ipynb  __pycache__\n",
            "downloader.py\t\t\t       pytorch3dunet\n",
            "git_clone\t\t\t       README.md\n",
            "model.py\t\t\t       ResampleImages.ipynb\n",
            "ModelTraining.ipynb\t\t       sample_data\n",
            "ModelTrainingWithMockdata.ipynb        UpsampleImages.ipynb\n",
            "NpyToNifti.ipynb\t\t       util\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmV2m6-yFWDt",
        "outputId": "1041790c-824a-4228-84ca-addc7dc4cd8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "IMG_DIR = os.path.join(BASE_DIR, IMG_FOLDER_NAME)\n",
        "LABEL_DIR = os.path.join(BASE_DIR, LABEL_FOLDER_NAME)\n",
        "\n",
        "IMG_FILES = os.listdir(IMG_DIR)\n",
        "LABEL_FILES = os.listdir(LABEL_DIR)\n",
        "\n",
        "def get_img_path(file): \n",
        "    return os.path.join(IMG_DIR, file)\n",
        "\n",
        "def get_label_path(file):\n",
        "    return os.path.join(LABEL_DIR, file)\n",
        "\n",
        "def case_to_file(case):\n",
        "    return case+'.npy'\n",
        "\n",
        "def file_to_case(file_name):\n",
        "    return file_name.split('.')[0]\n",
        "\n",
        "set(IMG_FILES).issubset(LABEL_FILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NG3r_9YnmpI",
        "outputId": "8baaadcf-3a8b-4a1f-aa05-34a7f5c0c25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/LiTS_sample/image_128 51\n",
            "/gdrive/MyDrive/LiTS_sample/mask_128 51\n"
          ]
        }
      ],
      "source": [
        "print(IMG_DIR, len(IMG_FILES))\n",
        "print(LABEL_DIR, len(LABEL_FILES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZTXvFCDnmpI",
        "outputId": "c51d519c-3870-4b57-fe74-0687014b4a68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(set(IMG_FILES)-set(LABEL_FILES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WAYgDdnQnmpI"
      },
      "outputs": [],
      "source": [
        "# # z축 작은 녀석들만 남기기 \n",
        "# SMALL_Z_CASES = ['000251_20190703_chest', '000356_20191024_chest', '000350_20190927_chest', '000397_20200214_chest', 'BH005_20170701_abdomen', 'BH041_20190201_C-T-L Spine (3D)', 'BH005_20170701_chest', '000355_20190901_abdomen', '000022_20180830_chest', '000244_20190501_abdomen', '000332_20191025_chest', '000019_20181018_chest', 'BH011_20190301_Spine^00_C_Spine_Pre_OP (Adult)', '000019_20190613_chest', 'BH017_20191201_abdomen', '000273_20190531_chest', '000404_20200305_chest', '000286_20190701_abdomen', 'SN015_20190901_chest', '000391_20200216_Thoracic Aorta CT Angio+3D (contrast)', '000262_20190501_abdomen', 'SN013_20190401_chest', '000285_20190807_chest', '000362_20191201_abdomen', '000322_20190913_chest', 'BH057_20191227_chest', '000400_20200210_chest', 'BH064_20200605_abdomen', 'BH034_20190901_chest', '000298_20190726_chest', '000311_20190902_chest', '000396_20200201_abdomen', '000223_20190319_chest', 'BH032_20180701_abdomen', '000291_20190701_abdomen', 'BH045_20181001_abdomen', '000296_20190726_chest', 'BH066_20190525_chest', 'BH010_20161101_chest', '000251_20190701_abdomen', 'SN007_20190701_chest', '000193_20190114_chest', '000262_20190529_chest', '000251_20190429_chest', 'BH060_20200413_chest', '000234_20190419_chest', 'BH040_20200101_CT Angio + 3D Pulmonary artery (Embolism) (2)', 'BH070_20160823_chest', '000316_20190627_chest', '000356_20190901_abdomen', '000383_20200121_chest', 'BH052_20190901_chest', '000450_20200512_chest', '000276_20190604_chest', '000364_20191217_chest', 'BH025_20191101_abdomen', 'BH035_20191101_GU Kidney & bladder CT (3D)', 'BH018_20190801_chest', '000269_20190601_abdomen', 'BH008_20190701_chest', '000332_20191001_abdomen', 'BH043_20191001_abdomen', '000260_20190522_chest', 'BH007_20190801_chest', 'BH067_20191017_chest', '000279_20190614_chest', 'SN004_20190901_chest', 'BH042_20180801_C-T-L Spine (3D)', 'BH099_20200806_abdomen', 'BH055_20200328_chest', 'BH001_20190401_chest', '000162_20180131_chest', 'BH054_20191122_abdomen', '000450_20200501_abdomen', 'BH030_20160101_T-L spine (3D)', '000372_20200107_chest', 'BH069_20200505_chest', 'BH012_20180401_abdomen', 'BH058_20180918_chest', '000404_20200201_abdomen', 'BH048_20190501_chest', '000348_20191201_CT Liver (contrast)', 'BH002_20190701_chest', '000376_20200101_abdomen', '000309_20190801_abdomen', 'SN017_20190701_chest', 'BH029_20200101_chest', 'BH059_20201013_abdomen', '000310_20190801_abdomen', '000272_20190614_chest', 'BH027_20191001_L-spine CT (3D)', 'BH064_20200605_chest', '000350_20191001_abdomen', '000232_20190423_chest', 'BH001_20190501_abdomen', 'BH039_20190601_chest', 'SN008_20190901_chest', '000270_20190608_chest', 'BH091_20200104_chest', '000269_20190604_chest', '000331_20190916_chest', '000325_20190919_chest', '000363_20191222_chest', '000260_20190501_CT Liver (contrast)', '000330_20190926_chest', 'BH072_20200219_abdomen', '000324_20190910_chest', 'BH009_20180301_chest', 'BH028_20190801_chest', 'SN029_20200301_chest', 'BH110_20200616_chest', '000401_20200201_T-Spine+3D CT (noncontrast)', 'SN031_20160501_chest', 'SN005_20191101_chest', '000452_20200513_chest', '000021_20181227_chest', '000236_20190401_abdomen', 'SN002_20190801_chest', '000382_20200129_chest', '000301_20190801_Pulmonary artery CT Angio+3D (contrast)', 'BH015_20190101_chest', 'BH043_20191001_chest', 'BH063_20200519_chest', '000363_20191201_abdomen', '000354_20191001_abdomen', 'BH047_20180901_abdomen', '000079_20180911_Pulmonary artery CT Angio+3D (contrast)', 'BH016_20151001_chest', 'BH061_20190315_abdomen', 'BH014_20181201_chest', '000362_20191214_chest', '000354_20191022_chest', 'SN051_20170401_chest', 'SN036_20190601_chest', 'BH017_20191201_chest', '000282_20190701_abdomen', 'BH023_20191101_chest', '000085_20180829_chest', 'SN019_20190801_chest', '000212_20190324_chest', '000302_20190726_chest', 'BH009_20180301_abdomen', 'BH008_20190701_abdomen', '000301_20190801_abdomen', 'BH015_20190101_abdomen', 'SN028_20160801_chest', '000344_20191125_chest', 'BH014_20181201_abdomen', '000214_20190325_chest', '000386_20200204_chest', '000372_20200101_abdomen', 'BH091_20200104_GU Kidney & bladder CT (3D)', 'SN025_20200401_chest', '000400_20200201_CT Biliary (contrast)', '000255_20190418_chest', 'BH081_20190322_abdomen', '000315_20190820_chest', '000288_20190701_abdomen', '000272_20190601_abdomen', '000322_20190901_abdomen', '000331_20190901_abdomen', 'SN055_20170301_chest', 'BH052_20190901_abdomen', '000310_20190812_chest', '000069_20180319_chest', 'BH024_20190501_abdomen', 'BH021_20181001_abdomen', '000009_20180417_chest', 'BH037_20171101_abdomen', '000002_20180829_chest', '000234_20190401_abdomen', '000262_20190318_chest', 'SN016_20190901_chest', '000232_20190401_abdomen', 'SN056_20170601_Thorax^01_Lung_Cancer_3D (Adult)', '000300_20190801_abdomen', 'BH006_20170801_chest', '000278_20190620_chest', 'BH036_20180301_GU Kidney & bladder CT (3D)', 'BH019_20191101_chest', 'BH004_20191101_chest', '000382_20200101_abdomen', '000242_20190409_chest', 'BH061_20190315_chest', '000080_20180911_chest', '000355_20191023_chest', '000364_20191201_abdomen', 'BH018_20190801_abdomen', '000291_20190718_chest', '000279_20190601_abdomen', '000308_20190826_chest', '000305_20190801_abdomen', 'BH010_20161101_abdomen', 'BH007_20190801_abdomen', 'BH021_20181001_chest', '000396_20200218_chest', '000091_20180504_chest', 'SN042_20170901_chest', '000314_20190827_chest', 'BH031_20160301_CT Angio + 3D Pulmonary artery (Embolism)', 'BH023_20191101_abdomen', '000301_20190827_chest', 'BH062_20201104_chest', 'BH020_20191201_chest', 'BH059_20201019_chest', '000246_20190629_chest', 'BH026_20190601_abdomen', 'BH040_20200101_CT Angio + 3D Pulmonary artery (Embolism)', 'BH034_20190901_abdomen', 'BH099_20200806_chest', 'BH051_20190301_GU Kidney & bladder CT (3D)', '000368_20200101_abdomen', 'BH057_20191227_abdomen', 'BH112_20190201_chest', 'BH024_20190501_chest', 'BH013_20191001_chest', '000309_20190823_chest', '000011_20181207_chest', 'BH020_20191201_abdomen', 'BH027_20191001_chest', '000316_20190715_Spine^L_SPINE (Adult)', '000012_20181214_chest', 'BH032_20180701_chest', 'BH037_20171101_chest', '000285_20190801_abdomen', 'BH038_20160901_CT angio + 3D C-spine(vertebral artery, C1-2)', 'BH072_20200219_chest', 'SN054_20170201_chest', '000048_20190501_abdomen', '000304_20190124_chest', 'BH045_20181001_chest', '000352_20191001_abdomen', 'BH016_20151001_abdomen', 'BH022_20190101_chest', 'BH047_20180901_chest', '000314_20190901_abdomen', 'BH065_20201013_chest', 'BH056_20200721_chest', '000281_20190701_chest', '000025_20180808_chest', '000352_20191017_chest', 'BH012_20180401_chest', '000224_20190228_chest', '000308_20190801_abdomen', '000376_20200114_chest']\n",
        "# SMALL_Z_FILES = [case_to_file(case) for case in SMALL_Z_CASES]\n",
        "# IMG_FILES = list(set(IMG_FILES).intersection(SMALL_Z_FILES))\n",
        "# len(IMG_FILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4uhIYxCUnmpK"
      },
      "outputs": [],
      "source": [
        "TRAIN_FILES = [f\"volume-{i}.npy\" for i in range(45)]\n",
        "VAL_FILES = [f\"volume-{i}.npy\" for i in range(45,51)]\n",
        "TEST_FILES = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kA83sFMRnmpL"
      },
      "outputs": [],
      "source": [
        "TRAIN_FILES = list(set(TRAIN_FILES) - set(VAL_FILES) - set(TEST_FILES))\n",
        "VAL_FILES = list(set(VAL_FILES))\n",
        "TEST_FILES = list(set(TEST_FILES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1YAA8IznmpL",
        "outputId": "42b6c7b3-0539-423f-d32f-0386f6a8fecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: 45\n",
            "val: 6\n",
            "test: 0\n",
            "total: 51\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'''\n",
        "train: {len(TRAIN_FILES)}\n",
        "val: {len(VAL_FILES)}\n",
        "test: {len(TEST_FILES)}\n",
        "total: {len(TRAIN_FILES + VAL_FILES + TEST_FILES)}\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UNDBJinfPD2q"
      },
      "outputs": [],
      "source": [
        "def adjust_window(image, window):\n",
        "    width = window[0]\n",
        "    level = window[1]\n",
        "    upper = level+width/2\n",
        "    lower = level-width/2\n",
        "    copied_image = image.clip(lower, upper)\n",
        "    copied_image = copied_image-lower\n",
        "    return (copied_image/(upper-lower))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghAI2GSKIofO"
      },
      "source": [
        "# Set dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F3CzRWsknmpL"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import time\n",
        "import os, glob\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from augmentation import get_transform\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, case_files=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.case_files = case_files\n",
        "        self.images = [np.load(get_img_path(file)) for file in case_files]\n",
        "        self.labels = [np.load(get_label_path(file)) for file in case_files]\n",
        "        self.windows = [(500,200), (700,400)]\n",
        "\n",
        "    def get_data_info(self):\n",
        "        all_data_info = pd.read_csv(f'{BASE_DIR}/data_info_V_2022_04_20.csv')\n",
        "        case_tuple = tuple([file_to_case(file) for file in self.case_files])\n",
        "        include_idx = all_data_info.Case.str.startswith(case_tuple)\n",
        "        return all_data_info.loc[include_idx]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.case_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.get_case(idx)\n",
        "    \n",
        "    def get_case(self, idx):\n",
        "        patch_image = self.images[idx]\n",
        "        patch_label = self.labels[idx]\n",
        "        return self.process_patch(patch_image, patch_label)\n",
        "\n",
        "    def process_patch(self, patch_image, patch_label):\n",
        "#         patch_image, patch_label = torch.tensor(patch_image, dtype=torch.float32), torch.tensor(patch_label, dtype=torch.bool)\n",
        "#         return self.convert_to_multi_channel_img(patch_image, self.windows), patch_label\n",
        "        augmentation_dict={'flip': True, 'scale':0.2, 'rotate':False,'offset': 0.1, 'noise': 0.1}\n",
        "        transformed_image, transformed_label = get_transform(patch_image, patch_label, augmentation_dict)\n",
        "        return self.convert_to_multi_channel_img(transformed_image, self.windows), transformed_label   \n",
        "    \n",
        "    def convert_to_multi_channel_img(self, image, windows):\n",
        "        adjusted_images = [adjust_window(image, window) for window in windows]\n",
        "        return torch.stack(adjusted_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PFnXk11InmpM"
      },
      "outputs": [],
      "source": [
        "class ValDataset(Dataset):\n",
        "    def __init__(self, case_files=None, ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            case_files (string): case filenames\n",
        "        Return:\n",
        "            one whole case\n",
        "\n",
        "        \"\"\"\n",
        "        self.case_files = case_files\n",
        "        self.images = [np.load(get_img_path(file)) for file in case_files]\n",
        "        self.labels = [np.load(get_label_path(file)) for file in case_files]\n",
        "        self.windows = [(500,200), (700,400)]\n",
        "\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.case_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.images[idx], self.labels[idx]\n",
        "        image_tensor = torch.tensor(image, dtype = torch.float32)\n",
        "        multi_channel_image = self.convert_to_multi_channel_img(image_tensor, self.windows)\n",
        "        return multi_channel_image, torch.tensor(label, dtype = torch.bool)\n",
        "\n",
        "    def convert_to_multi_channel_img(self, image, windows):\n",
        "        adjusted_images = [adjust_window(image, window) for window in windows]\n",
        "        return torch.stack(adjusted_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true,
        "id": "LMysXF4ynmpM"
      },
      "outputs": [],
      "source": [
        "# len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lnXswuiwnmpM"
      },
      "outputs": [],
      "source": [
        "def slice_img(img, offset, end, interval):\n",
        "  if end is None:\n",
        "    end = len(img)\n",
        "  else: \n",
        "    if end > len(img): \n",
        "      end = len(img)\n",
        "    if end <= offset:\n",
        "      end = offset + 1\n",
        "  return img[offset:end:interval]\n",
        "\n",
        "def show_numpy_img(np_img, offset=0, end=None, interval=5, title=''): \n",
        "  sliced_img = slice_img(np_img, offset, end, interval)\n",
        "\n",
        "  figsize_per_img = 3\n",
        "  num_col = 5\n",
        "  num_row = int(np.ceil(sliced_img.shape[0] / num_col))\n",
        "  # fig, axs = plt.subplots(num_row, num_col, figsize = (figsize_per_img*num_col, figsize_per_img*num_row))\n",
        "  plt.figure(figsize=(figsize_per_img*num_col, figsize_per_img*num_row))\n",
        "  for i, img in enumerate(sliced_img):\n",
        "    if i >= num_col*num_row:\n",
        "      continue\n",
        "    # axs[i].imshow(img)\n",
        "    plt.subplot(num_row, num_col, i+1)\n",
        "    plt.imshow(img, 'gray')\n",
        "    # plt.title()\n",
        "  plt.suptitle(title)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "#npy image 정보 보여주기 \n",
        "def show_img_info(np_img):\n",
        "  print('Shape:', np_img.shape)\n",
        "  print('DType:', np_img.dtype)\n",
        "  print('Max:', np_img.max())\n",
        "  print('Min:', np_img.min())\n",
        "  print(np_img)\n",
        "\n",
        "def plot_img_and_label(np_img, label, interval = 5, offset = 0, end=None, figsize_per_image = 5):\n",
        "  sliced_img = slice_img(np_img, offset, end, interval)\n",
        "  sliced_label = slice_img(label, offset, end, interval)\n",
        "  \n",
        "  num_row = len(sliced_img)\n",
        "  num_col = 2\n",
        "\n",
        "  plt.figure(figsize=(figsize_per_image*num_col, figsize_per_image*num_row))\n",
        "\n",
        "  for i in range(0, num_row):\n",
        "    plt.subplot(num_row, num_col, i*num_col+1)\n",
        "    tissue_image = sliced_img[i]\n",
        "    plt.imshow(tissue_image, 'gray')\n",
        "\n",
        "    plt.subplot(num_row, num_col, i*num_col+2)\n",
        "    mask = sliced_label[i]\n",
        "    label_on_tissue = sitk.LabelMapContourOverlay(sitk.Cast(sitk.GetImageFromArray(mask), sitk.sitkLabelUInt8), sitk.GetImageFromArray(tissue_image), opacity=0.7, contourThickness=[2,2], colormap=(0,255,0))\n",
        "    plt.imshow(sitk.GetArrayFromImage(label_on_tissue), 'gray')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vxyWGOxDnmpM"
      },
      "outputs": [],
      "source": [
        "# img, label = train_dataset[0]\n",
        "# plot_img_and_label(img[0].type(torch.int16).numpy(), label.type(torch.uint8).numpy())\n",
        "\n",
        "# # plot_img_and_label(*train_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ozUJqsdu6gGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2352c030-4b8f-49ed-9cbe-c0d460781017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "consumed_time: 0.6043708919996789s\n",
            "train: 45\n",
            "val: 6\n",
            "\n"
          ]
        }
      ],
      "source": [
        "t = time.perf_counter()\n",
        "\n",
        "train_dataset = TrainDataset(TRAIN_FILES)\n",
        "val_dataset = ValDataset(VAL_FILES)\n",
        "\n",
        "elapsed_time = time.perf_counter() - t\n",
        "\n",
        "print(f'''\n",
        "consumed_time: {elapsed_time}s\n",
        "train: {len(train_dataset)}\n",
        "val: {len(val_dataset)}\n",
        "''')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "cGOP-nkobJN_",
        "outputId": "c3a73b9d-574e-412e-bc9f-d3c0918f2b56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f04b0b90ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample_train = train_dataset[9]\n",
        "plt.imshow(sample_train[0][1][PATCH_SIZE//2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "BhG5M7KJfyx9",
        "outputId": "f21c5e26-abeb-43bf-fa43-d198f1f004ca",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f04b0663a90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZuklEQVR4nO3de3hV5Zn38e+9d06cEhKOkYCgIoiIAlEOTq2VWq31FWfGWhyngtJh2tGqrTMVa6f2nfd1Lm2tp1arjIdBBw+IJ8baWqU62kpREBUEhQgCQSCAHAVCkn3PH3shgSQQ9jlZv891cWXvZ621183K3r8867DXY+6OiIRXJNsFiEh2KQREQk4hIBJyCgGRkFMIiIScQkAk5NIWAmZ2rpl9ZGZVZjY1XesRkeRYOq4TMLMosAw4G6gG3gYucfclKV+ZiCQlL02vexpQ5e4rAMzsCWA80GwIFFihF9EpTaWICMAOtmxy9x4Ht6crBPoAaxo9rwZGNZ7BzKYAUwCK6MgoG5emUkQE4BWftaq59qwdGHT3ae5e6e6V+RRmqwyR0EtXCKwF+jZ6XhG0iUiOSVcIvA0MNLMBZlYATABmp2ldIpKEtBwTcPd6M7sKeAmIAg+5+wfpWJeIJCddBwZx9xeBF9P1+iKSGrpiUCTkFAIiIacQEAk5hYBIyCkEREJOISAScgoBkZBTCIiEnEJAJOQUAiIhpxAQCTmFgEjIKQREQk4hIBJyCgGRkFMIiIScQkAk5BQCIiGnEBAJOYWASMgpBERCTiEgEnIKAZGQUwiIhJxCQCTkEg4BM+trZq+a2RIz+8DMrgnay8zsZTNbHvwsTV25IpJqyfQE6oHr3H0IMBq40syGAFOBOe4+EJgTPBeRHJVwCLj7Ond/J3i8A1gK9AHGA9OD2aYDFyZbpIikT0oGJDWz/sBwYB7Qy93XBZPWA71aWGYKMAWgiI6pKENEEpD0gUEz6ww8DVzr7tsbT3N3B7y55dx9mrtXuntlPoXJliEiCUoqBMwsn3gAzHD3Z4LmDWZWHkwvB2qSK1FE0imZswMGPAgsdffbG02aDUwMHk8Enk+8PBFJt2SOCZwOfBtYZGbvBm0/Bm4BZprZZGAVcHFyJYpIOiUcAu7+J8BamDwu0dcVkczSFYMiIacQEAk5hYBIyCkEREJOISAScgoBkZBTCIiEnEJAJOQUAiIhpxAQCTmFgEjIKQREQk4hIBJyCgGRkFMIiIScQkAk5BQCIiGnEBAJOYWASMgpBERCTiEgEnIKAZGQUwiIhJxCQCTkFAIiIZeKUYmjZrbQzF4Ing8ws3lmVmVmT5pZQfJliki6pKIncA2wtNHzW4E73P04YAswOQXrEJE0SXZo8grgG8ADwXMDzgJmBbNMBy5MZh0ikl7J9gTuBH4ExILn3YCt7l4fPK8G+jS3oJlNMbP5Zja/jtokyxCRRCUcAmZ2PlDj7gsSWd7dp7l7pbtX5lOYaBkikqSEhyYHTgcuMLPzgCKgGLgL6GpmeUFvoAJYm3yZIpIuCfcE3P0Gd69w9/7ABOCP7n4p8CpwUTDbROD5pKsUkbRJx3UC1wM/NLMq4scIHkzDOkQkRZLZHfiCu78GvBY8XgGclorXFZH00xWDIiGnEBAJOYWASMgpBERCTiEgEnIKAZGQUwiIhJxCQCTkFAIiIacQEAk5hYBIyCkEREJOISAScgoBkZBTCIiEnEJAJOQUAiIhpxAQCTmFgEjIKQREQk4hIBJyCgGRkFMIiIRcSsYdEBGIdu/Gji8dhzfzp7XTml3w1qLMF9UKCgGRFNkzYgBP3307JZGCJtOG/Wky/b+VhaJaIandATPramazzOxDM1tqZmPMrMzMXjaz5cHP0lQVK5KLIkVFrPnXsayfsoeSSAGFlt/k3xVD5rL8V6OIfWl4tsttItljAncBv3f3wcDJwFJgKjDH3QcCc4LnIu2WFRVy+bdeYsnY/6LQ8pud5/puy1nxt/dTM7IDVliY4QoPLeEQMLMS4AyCAUfdfa+7bwXGA9OD2aYDFyZbpEh7cd13Z1Lwh1LyBhyd7VK+kExPYACwEXjYzBaa2QNm1gno5e7rgnnWA72aW9jMppjZfDObX0dtEmWIZE/eMf3Zc9pAeuTtaNX8lxVv4t/6PY93LEpzZa2XzIHBPGAE8H13n2dmd3FQ19/d3cy8uYXdfRowDaDYypqdRyTXLZnagzfOvYNe0Q5ANNvlJCSZnkA1UO3u84Lns4iHwgYzKwcIftYkV6JI7okMHcyaG8dy5rAPqcjrTL61PgC6R+tYdkUpWy8bk8YKWy/hEHD39cAaMxsUNI0DlgCzgYlB20Tg+aQqFMlBmytLWXLlvTzc740jXrYirzNVl9xH+eQVEMl+7yHZ6wS+D8wwswJgBXA58WCZaWaTgVXAxUmuQ0TSKKkQcPd3gcpmJo1L5nVFclYkSt7RFewps2xXkjK6YlDkCOT1KafyuSp+XvIE0CHb5aSEvkAk0kp7z6lkzcX9+OvidzixoH0EAKgnINJqe3/wGe8PewbIrSv+kqWegEjIqScgchhWWEikcycKog3ZLiUt1BMQOYyNk0bwjTeW89DxM7JdSlqoJyDSgkiXLuw5fTCfDW/gyq5rgM7ZLiktFAIiLYid0J+77vsVg/KjQPNfEW4PFAIiB4tEWX/NKHacsoej87zFewS0FwoByQ2RKBYNrqP3GF5fn7VSLD+P0Zcs5P6KubSXC4IORQcGJSes+fEoyt8opPyNQqoeGUqkKHe+b9/eqScgaRcpKsJPOBaiLV9vHxmx7Ytv5N3eeS2/qzyD6J54byCybDUN27enqbgokSED8aL9H4VYQZQeBe+kZ305SCEg6Tf4GL7/1NMMzN/c4iy9ohH2db2vLP2I8TPepwGjziP843XX0unpeS0um4xoaQmnPLqESWVz97fhVOQV0p4PBjamEJC0iH15OOtPjX+o9/R0Ti3cTM9op1YtW2j5HJsf/wA2eIy1X2+grPsYej76HrFduxKqZ8e3RrOjb9O934YimFpyL8fnt6629kghIGmx8vwiqi69t1FLYh+yqEVYed4DPPGlUh59YUxiIWBGlynVvHnCCwnV0N4pBCSlrHIoG/61nn869qWs1hEdcjxrbs6jQ0EdEXNu6f9MVuvJZQoBSQ0z8nr3YtMJXXhj5B10jmT+6H60awlWUgzA9sGlzKm8vdW7IJnU4DEW7a1jzfYSunv2b8GpEJCUiJYU0+mpOn581D1ZCQCAquuHcNtF8SEvukZ30S2Sm+f4P6yr5dorr6b3onXUe/ZvtK0QkNSwCGNLP+b0osxfepJX0YfNZ/al2yk1XNCp8TGD3LwMps4jdFy1nfo11dkuBVAISDuwdUwFf7zlbjo2MxCoHJ5CQHJag8cY9NpkOi7oQJ+t7x0wLVpczPKfnEivYRsoNL2VE6UtJzmnzhvY1LA7/hjo/WwBnWa9Seyg+axTR342fiaXdtlMrnb92wKFgOSce7Yey+wffJVobQPEoHjJctrnPX1yg0JAkhYdcjw7j+9K77x3W73MrthefrXlRD6rb3oK74UVJ9Lv9cXE9uwBaDYAIkMHs21wCT2icxItu9Xeqq3jua0jubR0Xru6y/A+CgFJ2ofXd2bBWXdSHCmitd3yxXXGa98+FZZ90mRa34YqYrWHHql65U/zmTf2TjpbYavXmai/nzeZY6+o4s3nLuG1oc+ldV3ZkFQImNkPgO8ADiwiPgxZOfAE0A1YAHzb3fcmWafkIBt+Iiu+WcwFQ9+mNNrxiJaNeQSrraPhSC8DHj2MlRd04pJBr1OSoesA/s/Axfz3T0bx3aOSvwrynKXn8/G7FQzavDIFlaVGwiFgZn2Aq4Eh7r7bzGYCE4DzgDvc/Qkzuw+YDPwmJdVK9piBHfgXd9PIYpZNOvJfbYPH2EsUYkd+ocyGUzuzbNK9h58xhX5Z/g6/nJSarxbXPNOPY+95k+zdMqWpZHcH8oAOZlYHdATWAWcBfxdMnw78DIVAm7flstH0+87yA9rO6vpKQq818NnvUfGy06n6g1SUJklKOATcfa2Z3QasBnYDfyDe/d/q7vuCrhro09zyZjYFmAJQxJF1JSUzoscNwDvGR9vZfLLz1rGJfegP1nVxhA7Pz21yyu9QLL+AyMD+7OmR/ctsE7G6fidv7u5L/s7cqz+Z3YFSYDwwANgKPAWc29rl3X0aMA2g2Mpyb8uEnBUWUvDgLn7W7wkAukfryOYttyMD+zPhmT9yZsdPslpHoi58dzLl39tBt80Ljyj8MiGZ3YGvAivdfSOAmT0DnA50NbO8oDdQAaxNvkzJpNiXh7NhZAf+uddMTincN+5edsff87wIwwrX0i+v7QUAwJ69+dSv/TTbZTQrmRBYDYw2s47EdwfGAfOBV4GLiJ8hmAg8n2yRklkfX1TAir/N7ME3yZ5kjgnMM7NZwDtAPbCQePf+t8ATZvb/g7YHU1GotH2Xr/4SCx87iaPe2ByaKwD/vCfGlP+4ip7v1WW7lBYldXbA3W8CbjqoeQVwWjKvK9lh+QVEu5XiRenZa31z1QD63/1maAIA4OO9Pen/8MfUr9+Q7VJapCsG5Qu1405m4p3PM6roWdAZm9BQCMgX6jtEuKTLWgotPQEwqHcNmy8eTde3PqX+k9WHnT865Hi2DS0DYGd5hJJIHdk+QHkkflJzEs9+PIyja3PzgOA+CgHJmGePe5HYHc7of7uK7vcfPgQ+vrQbiyf9+ovn+dZ2zgzUeh2v3jyWiqfn0xDL7R0ghYB8ocuHnzHs4asZ+ZUPeWzAqyl//ahFiALezEBEWy8bQ83YAz8sZ56ymHyLpryOTLEYkOMBAAoBCUSKivBVaznm39cyt9tQSEMINL/iKJGiQjaetZeVX9OJpGxQCAjRbmVsm9GVsT3j32z755LMfRhrzx3ByP+3gJ+U/ge6O1B2KAQE8vL4h/5/YlJx5u6Bb/kF+MjB1IzI5+e95xO1th8A6+p38si24dR5lDqPUrAtl74r2DKFgGRFtHdPxj/8Ct/sXEU0TWcjMu3OzX/FonN7wu74HZHyd7b+TkvZpBAIuZ3fHMXGkRGGFP6WTI3CW3v2dpYd05fTOzx1xDcjyWX1sQi+bfsXt0VrKxQCYWbGZxfvYtnpj5LJYbg/GDMDxsC+ocjbgwaP0dBGj2koBEJq9/jT6HD1p9x29FPZLqXN29TwOWfc/y/0XFhHYe38bJdzxBQCIZJX0QfvFP/ru+mkPJZoqO6kLd27izd2D6TfSzvwtxdlu5yEKATCwox193bm3qGPAdAjupu2eHOOXHPBk9dx/K/XwPqPsl1KwhQC7Vhe715sOP8YPBq/Su9v+r/K6KJ9V+ApAFIhf6flzMCiiVIItGO1J/ThxZtuo2e06QAfIvsoBNoJH3MyK79vmO2/XWPvsi2UaKTetPj3TYN4bMY4Kl7/PNulJE0hkIOipaWQd2S/mpohHVny5V8384WbzJ36a+/W1e9kR/Dtp1mfnEKfW9/MckWpoRDIMZEuXah9qgvf6nNkp5r65b/epr9x1xac9cCPOPrF7QD03rar3dwhSSGQQyInn8C2wSVc3fdJJnTZku1yJPDa7giPbhxLj/fr8fmLgeYHSW2rFAI55MNrOvHB1+6mo/bjc8qUt77NMZctpUP929kuJS0UAjnEIq4AyAF13sBJf55E/Zr4WZXuC8Hr2u+YugoBEeLX/td6PTFi7IjV03t6EYW//Uu2y8oIhYAIcOvmE/j9T79MpM7BoeNbK9rVfv+hKAQkNHbF9vL4jn7sijW9Y/FjVZVUvPAOXh+/EUhYAgAUAhIif9rTiVkTvoJVNx0IpF/dGhrq28adgFLtsCFgZg8B5wM17j40aCsDngT6A58AF7v7FjMz4C7gPGAXMMnd30lP6e1P6dwCjsu/HICjum9lztBZOvefpF98diz3v3cGALGtBQyuXk7D5s+yXFVuaU1P4D+BXwOPNGqbCsxx91vMbGrw/Hrg68DA4N8o4DfBT2mF7vfPpfv98cd7z6lk14N7KbH2c+ONbLj3ra9w/BX7L7wKUze/tQ57KxR3fx04ODrHA9ODx9OBCxu1P+JxfyE+THl5qooNk47vV/PVn/6Q4W9PyHYpbdJzn3dm+M3/xHEP62N/OIkeE+jl7uuCx+uBXsHjPsCaRvNVB23rOIiZTQGmABRp3Lsm6tetp+yh9ayuGMufT4oxtKCWkoh6BYeyun4nn9THvyI9s+ZUej+yiNiOHVmuKvclfWDQ3d0af3Wt9ctNIz6UOcVWdsTLh8WAXy3l5icvpv9/VXNvn3Cct07Umf99HYPv3AiA7a0jtrNtf88/UxINgQ1mVu7u64Lu/r4b1q8F+jaaryJokwQ1bNkC27bz+7mVTBjZkQeOfpHOkaJsl5UTdsb2cMUn32Dj7vhf/7KFERqWr8hyVW1PordHnQ1MDB5PBJ5v1H6ZxY0GtjXabZBExRoYePU8tl5Vzqp6dZr2WVEPO67qRcHZqyg4exXdHpib7ZLapNacInwcOBPobmbVwE3ALcBMM5sMrAIuDmZ/kfjpwSripwgvT0PNoRWprmHCPddhp2/h/dMe58S5l1K3rJhZl9zBsIL21zu4eMU4Fv9uUIvTo3uhb3XbvbdfrjhsCLj7JS1MGtfMvA5cmWxR0ryGjRs56hcb2bBnLNUjdlL0h2L6z17J/1wwiLLIB03mLzDL2VuLNXiMmoZDfyd//jvHMfDmQ9+4Q8f+k2fxz212FVuZj7ImmSItyOvdi7pjy8mr+pTY5s/glMHECpvm+aaTOjDnxl/m5Cg/7+/dw3evv5bO1S2P1pP/6RbqV67KYFXt2ys+a4G7Vx7crsuG26D69Ruw9Rv2/xWcvxhrZr6etUO5pvpcygp2fdFWmreLf+n2bsJfWZ627SiW7DoqoWUbW7a9J6XzPqX+k9UtzhPOi3gzTyHQjvmCD9j4lUI2Nv41Dz6Fpc++y8im36FplWm3j6fHowuTr80347W1Sb+OJE8h0J65NxkcM7puExOeuoaGTrEEXg8GLvq8zQ24KYemEAiZhg01HPOjmsPPKKHRNodRFZGUUQiIhJxCQCTkFAIiIacQEAk5hYBIyCkEREJOISAScgoBkZBTCIiEnEJAJOQUAiIhpxAQCTmFgEjIKQREQk4hIBJyCgGRkFMIiIScQkAk5BQCIiF32BAws4fMrMbMFjdq+4WZfWhm75vZs2bWtdG0G8ysysw+MrNz0lW4iKRGa3oC/wmce1Dby8BQdx8GLANuADCzIcAE4MRgmXvNLJqyakUk5Q4bAu7+OvDZQW1/cPd9A8T8hfgQ5ADjgSfcvdbdVxIfmPS0FNYrIimWimMCVwC/Cx73AdY0mlYdtDVhZlPMbL6Zza9DI9GIZEtSIWBmNxIfMm7GkS7r7tPcvdLdK/NJcEwsEUlawiMQmdkk4HxgnO8f2ngt0LfRbBVBm4jkqIR6AmZ2LvAj4AJ339Vo0mxggpkVmtkAYCDwVvJliki6HLYnYGaPA2cC3c2sGriJ+NmAQuBlMwP4i7t/190/MLOZwBLiuwlXuntD868sIrnA9vfks6fYynyUjct2GSLt2is+a4G7Vx7crisGRUJOISAScgoBkZBTCIiEnEJAJOQUAiIhpxAQCbmcuE7AzDYCnwObsl0L0B3V0ZjqOFBbruNod+9xcGNOhACAmc1v7kIG1aE6VEd669DugEjIKQREQi6XQmBatgsIqI4DqY4Dtbs6cuaYgIhkRy71BEQkCxQCIiGXEyFgZucG4xRUmdnUDK2zr5m9amZLzOwDM7smaC8zs5fNbHnwszRD9UTNbKGZvRA8H2Bm84Jt8qSZFWSghq5mNisYU2KpmY3JxvYwsx8Ev5PFZva4mRVlanu0MM5Gs9vA4u4OanrfzEakuY70jPfh7ln9B0SBj4FjgALgPWBIBtZbDowIHnchPn7CEODnwNSgfSpwa4a2ww+Bx4AXguczgQnB4/uA72WghunAd4LHBUDXTG8P4nenXgl0aLQdJmVqewBnACOAxY3amt0GwHnE77RtwGhgXprr+BqQFzy+tVEdQ4LPTSEwIPg8RVu9rnS/sVrxnx0DvNTo+Q3ADVmo43ngbOAjoDxoKwc+ysC6K4A5wFnAC8GbalOjX/gB2yhNNZQEHz47qD2j24P9t60vI377uxeAczK5PYD+B334mt0GwP3AJc3Nl446Dpr218CM4PEBnxngJWBMa9eTC7sDrR6rIF3MrD8wHJgH9HL3dcGk9UCvDJRwJ/Ebt8aC592Arb5/gJdMbJMBwEbg4WC35AEz60SGt4e7rwVuA1YD64BtwAIyvz0aa2kbZPO9m9B4H83JhRDIKjPrDDwNXOvu2xtP83ispvUcqpmdD9S4+4J0rqcV8oh3P3/j7sOJf5fjgOMzGdoepcRHshoAHAV0oukweFmTiW1wOMmM99GcXAiBrI1VYGb5xANghrs/EzRvMLPyYHo5UJPmMk4HLjCzT4AniO8S3AV0NbN9d4POxDapBqrdfV7wfBbxUMj09vgqsNLdN7p7HfAM8W2U6e3RWEvbIOPv3UbjfVwaBFLSdeRCCLwNDAyO/hYQH9B0drpXavF7pT8ILHX32xtNmg1MDB5PJH6sIG3c/QZ3r3D3/sT/739090uBV4GLMljHemCNmQ0KmsYRv3V8RrcH8d2A0WbWMfgd7asjo9vjIC1tg9nAZcFZgtHAtka7DSmXtvE+0nmQ5wgOgJxH/Oj8x8CNGVrnXxHv1r0PvBv8O4/4/vgcYDnwClCWwe1wJvvPDhwT/CKrgKeAwgys/xRgfrBNngNKs7E9gP8LfAgsBh4lftQ7I9sDeJz4sYg64r2jyS1tA+IHcO8J3reLgMo011FFfN9/3/v1vkbz3xjU8RHw9SNZly4bFgm5XNgdEJEsUgiIhJxCQCTkFAIiIacQEAk5hYBIyCkERELufwHUOCVGcy9lJAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(sample_train[1][PATCH_SIZE//2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE6jDD9rgy4S"
      },
      "source": [
        "# Dataloader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szCOieSb6tj3",
        "outputId": "b2b09371-ba6b-4abc-abce-c8728de5dbe4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import multiprocessing\n",
        "multiprocessing.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "faTuO1ZW2eN4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "# NUM_WORKERS = multiprocessing.cpu_count()\n",
        "NUM_WORKERS = multiprocessing.cpu_count()\n",
        "\n",
        "def initTrainDl(train_ds, batch_size = BATCH_SIZE):\n",
        "    if USE_CUDA:\n",
        "        batch_size *= torch.cuda.device_count()\n",
        "\n",
        "    train_dl = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=USE_CUDA,\n",
        "        shuffle=True,\n",
        "        drop_last=False # to prevent gradient exploding\n",
        "    )\n",
        "    return train_dl\n",
        "\n",
        "def initValDl(val_ds, batch_size = BATCH_SIZE):\n",
        "    val_dl = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=USE_CUDA,\n",
        "    )\n",
        "    return val_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E26saJkd_CSC"
      },
      "source": [
        "# Set for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XFCCB0Vs_tU-"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "log = logging.getLogger(\"3DUnet\")\n",
        "# log.setLevel(logging.WARN)\n",
        "# log.setLevel(logging.INFO)\n",
        "log.setLevel(logging.DEBUG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6M8rm4z0EB9P"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "# For logging \n",
        "trn_writer = None\n",
        "val_writer = None\n",
        "# TB_PREFIX = img_type + \"_fn0\"\n",
        "time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H.%M.%S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lWgh1Szb-obt"
      },
      "outputs": [],
      "source": [
        "# Used for computeClassificationLoss and logMetrics to index into metrics_t/metrics_a\n",
        "# METRICS_LABEL_NDX = 0\n",
        "METRICS_LOSS_NDX = 1\n",
        "# METRICS_FN_LOSS_NDX = 2\n",
        "# METRICS_ALL_LOSS_NDX = 3\n",
        "\n",
        "# METRICS_PTP_NDX = 4\n",
        "# METRICS_PFN_NDX = 5\n",
        "# METRICS_MFP_NDX = 6\n",
        "METRICS_TP_NDX = 7\n",
        "METRICS_FN_NDX = 8\n",
        "METRICS_FP_NDX = 9\n",
        "\n",
        "METRICS_SIZE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZA_s68FvDKY",
        "outputId": "3ce1f3d1-cb9d-44f1-cabd-8075efc1c56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-04 05:49:28,685 INFO     pid:15041 3DUnet:011:initModel Using CUDA; 1 devices.\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import SGD, AdamW, RMSprop\n",
        "from torch import nn\n",
        "from pytorch3dunet.unet3d.model import ResidualUNet3D, DropResidualUNet3D\n",
        "\n",
        "def initModel():    \n",
        "    segmentation_model = DropResidualUNet3D(in_channels=2, out_channels=2, num_groups=FILTER_NUM, f_maps=FILTER_NUM, final_sigmoid=True, testing=True, num_levels=LEVELS)\n",
        "\n",
        "    # augmentation_model = SegmentationAugmentation(**self.augmentation_dict)\n",
        "\n",
        "    if USE_CUDA:\n",
        "        log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            segmentation_model = nn.DataParallel(segmentation_model)\n",
        "            # augmentation_model = nn.DataParallel(augmentation_model)\n",
        "        segmentation_model = segmentation_model.to(DEVICE)\n",
        "        # augmentation_model = augmentation_model.to(DEVICE)\n",
        "\n",
        "    return segmentation_model #, augmentation_model\n",
        "\n",
        "def initOptimizer():\n",
        "    return AdamW(segmentation_model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
        "    # return SGD(segmentation_model.parameters(), lr=0.001, momentum=0.99)\n",
        "\n",
        "segmentation_model = initModel()\n",
        "optimizer = initOptimizer()\n",
        "\n",
        "# Load model\n",
        "if MODEL_TO_LOAD :\n",
        "  model_folder = os.path.join(BASE_DIR, 'models')\n",
        "  model_path = os.path.join(model_folder, MODEL_TO_LOAD)\n",
        "  seg_dict = torch.load(model_path, map_location='cpu')\n",
        "  if torch.cuda.device_count() > 1:\n",
        "    segmentation_model.module.load_state_dict(seg_dict['model_state'])\n",
        "  else:\n",
        "    segmentation_model.load_state_dict(seg_dict['model_state'])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC0WXDOQnmpO",
        "outputId": "c6452fc5-977a-43db-beed-5a3d7bd44446"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DropResidualUNet3D(\n",
              "  (encoders): ModuleList(\n",
              "    (0): Encoder(\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(1, 2, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(2, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 24, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 24, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Encoder(\n",
              "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 24, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 48, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 48, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (2): Encoder(\n",
              "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 48, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Encoder(\n",
              "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 192, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 192, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (4): Encoder(\n",
              "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 192, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(192, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 384, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 384, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoders): ModuleList(\n",
              "    (0): Decoder(\n",
              "      (upsampling): TransposeConvUpsampling(\n",
              "        (upsample): ConvTranspose3d(384, 192, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      )\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 192, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 192, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 192, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Decoder(\n",
              "      (upsampling): TransposeConvUpsampling(\n",
              "        (upsample): ConvTranspose3d(192, 96, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      )\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (2): Decoder(\n",
              "      (upsampling): TransposeConvUpsampling(\n",
              "        (upsample): ConvTranspose3d(96, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      )\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 48, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 48, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 48, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Decoder(\n",
              "      (upsampling): TransposeConvUpsampling(\n",
              "        (upsample): ConvTranspose3d(48, 24, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      )\n",
              "      (basic_module): DropResNetBlock(\n",
              "        (conv1): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 24, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 24, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "          (ReLU): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): SingleConv(\n",
              "          (groupnorm): GroupNorm(24, 24, eps=1e-05, affine=True)\n",
              "          (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (non_linearity): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (final_conv): Conv3d(24, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "  (final_activation): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "segmentation_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0BzuYwBnmpO",
        "outputId": "6cd40f53-419b-48a1-b4b5-c8e3c00eb07e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19867470"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "count_parameters(segmentation_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TeQVaciD_4zd"
      },
      "outputs": [],
      "source": [
        "from util.util import enumerateWithEstimate\n",
        "from monai.losses import DiceLoss\n",
        "\n",
        "def doTraining(epoch_ndx, train_dl):\n",
        "    trnMetrics_g = torch.zeros(METRICS_SIZE, len(train_dl.dataset), device=DEVICE)\n",
        "    segmentation_model.train()\n",
        "    # train_dl.dataset.shuffleSamples() - 정의에서 처리했음\n",
        "\n",
        "    batch_iter = enumerateWithEstimate(\n",
        "        train_dl,\n",
        "        \"E{} Training\".format(epoch_ndx),\n",
        "        start_ndx=train_dl.num_workers,\n",
        "    )\n",
        "    for batch_ndx, batch_tup in batch_iter:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss_var = computeBatchLoss(batch_ndx, batch_tup, train_dl.batch_size, trnMetrics_g)\n",
        "        loss_var.backward()\n",
        "        \n",
        "        # Gradient clipping \n",
        "        max_norm = 5\n",
        "        torch.nn.utils.clip_grad_norm_(segmentation_model.parameters(), max_norm)\n",
        "        optimizer.step()\n",
        "    global totalTrainingSamples_count\n",
        "    totalTrainingSamples_count += trnMetrics_g.size(1)\n",
        "\n",
        "    return trnMetrics_g.to('cpu')\n",
        "\n",
        "def doValidation(epoch_ndx, val_dl):\n",
        "    with torch.no_grad():\n",
        "        valMetrics_g = torch.zeros(METRICS_SIZE, len(val_dl.dataset), device=DEVICE)\n",
        "        segmentation_model.eval()\n",
        "\n",
        "        batch_iter = enumerateWithEstimate(\n",
        "            val_dl,\n",
        "            \"E{} Validation \".format(epoch_ndx),\n",
        "            start_ndx=val_dl.num_workers,\n",
        "        )\n",
        "        for batch_ndx, batch_tup in batch_iter:\n",
        "            computeBatchLossVal(batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
        "\n",
        "    return valMetrics_g.to('cpu')\n",
        "\n",
        "def computeBatchLoss(batch_ndx, batch_tup, batch_size, metrics_g,\n",
        "                      classificationThreshold=0.5):\n",
        "    input_t, label_t= batch_tup\n",
        "    \n",
        "    input_g = input_t.to(DEVICE, non_blocking=True)\n",
        "    label_g = label_t.to(DEVICE, non_blocking=True).unsqueeze(1)\n",
        "\n",
        "    # if segmentation_model.training and augmentation_dict:\n",
        "    #     input_g, label_g = augmentation_model(input_g, label_g)\n",
        "\n",
        "    prediction_g_multi_ch = segmentation_model(input_g)\n",
        "#     prediction_g = prediction_g_multi_ch[:,0] # B, C, D, H, W -> B, D, H, W\n",
        "    prediction_g = prediction_g_multi_ch\n",
        "    diceLoss_g = diceLoss(prediction_g, label_g)\n",
        "    fnLoss_g = diceLoss(prediction_g * label_g, label_g)\n",
        "    ceLoss = nn.CrossEntropyLoss()\n",
        "    ceLoss_g = ceLoss(prediction_g, label_g.squeeze(1).long())\n",
        "    start_ndx = batch_ndx * batch_size\n",
        "    end_ndx = start_ndx + input_t.size(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictionBool_g = (prediction_g > classificationThreshold).to(torch.float32)\n",
        "\n",
        "        tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3,4])\n",
        "        fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3,4])\n",
        "        fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3,4])\n",
        "\n",
        "        metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = diceLoss_g\n",
        "        metrics_g[METRICS_TP_NDX, start_ndx:end_ndx] = tp\n",
        "        metrics_g[METRICS_FN_NDX, start_ndx:end_ndx] = fn\n",
        "        metrics_g[METRICS_FP_NDX, start_ndx:end_ndx] = fp\n",
        "\n",
        "    return diceLoss_g.mean() + ceLoss_g + fnLoss_g.mean() * FN_LOSS \n",
        "\n",
        "def computeBatchLossVal(batch_ndx, batch_tup, batch_size, metrics_g,\n",
        "                      classificationThreshold=0.5):\n",
        "    input_t, label_t= batch_tup\n",
        "    \n",
        "    input_g = input_t.to(DEVICE, non_blocking=True)\n",
        "    label_g = label_t.to(DEVICE, non_blocking=True).unsqueeze(1)\n",
        "\n",
        "    prediction_g_multi_ch = segmentation_model(input_g)\n",
        "#     prediction_g = prediction_g_multi_ch[:,0] # B, C, D, H, W -> B, D, H, W\n",
        "    prediction_g = prediction_g_multi_ch\n",
        "    diceLoss_g = diceLoss(prediction_g, label_g)\n",
        "    start_ndx = batch_ndx * batch_size\n",
        "    end_ndx = start_ndx + input_t.size(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictionBool_g = (prediction_g > classificationThreshold).to(torch.float32)\n",
        "\n",
        "        tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3,4])\n",
        "        fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3,4])\n",
        "        fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3,4])\n",
        "\n",
        "        metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = diceLoss_g\n",
        "        metrics_g[METRICS_TP_NDX, start_ndx:end_ndx] = tp\n",
        "        metrics_g[METRICS_FN_NDX, start_ndx:end_ndx] = fn\n",
        "        metrics_g[METRICS_FP_NDX, start_ndx:end_ndx] = fp\n",
        "\n",
        "    return diceLoss_g.mean()\n",
        "\n",
        "diceLoss = DiceLoss(to_onehot_y=True, include_background=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "UKwQWwI-xoGl",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def logMetrics(epoch_ndx, mode_str, metrics_t, tb_type = TB_PREFIX):\n",
        "    log.info(\"E{} {} {}\".format(\n",
        "        epoch_ndx,\n",
        "        \"Unet\",\n",
        "        tb_type\n",
        "    ))\n",
        "\n",
        "    metrics_a = metrics_t.detach().numpy()\n",
        "    sum_a = metrics_a.sum(axis=1)\n",
        "    assert np.isfinite(metrics_a).all()\n",
        "\n",
        "    allLabel_count = sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]\n",
        "\n",
        "    metrics_dict = {}\n",
        "    metrics_dict['loss/all'] = metrics_a[METRICS_LOSS_NDX].mean()\n",
        "\n",
        "    metrics_dict['percent_all/tp'] = \\\n",
        "        sum_a[METRICS_TP_NDX] / (allLabel_count or 1) * 100 \n",
        "    metrics_dict['percent_all/fn'] = \\\n",
        "        sum_a[METRICS_FN_NDX] / (allLabel_count or 1) * 100\n",
        "    metrics_dict['percent_all/fp'] = \\\n",
        "        sum_a[METRICS_FP_NDX] / (allLabel_count or 1) * 100\n",
        "\n",
        "\n",
        "    precision = metrics_dict['pr/precision'] = sum_a[METRICS_TP_NDX] \\\n",
        "        / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FP_NDX]) or 1)\n",
        "    recall    = metrics_dict['pr/recall']    = sum_a[METRICS_TP_NDX] \\\n",
        "        / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]) or 1)\n",
        "\n",
        "    metrics_dict['pr/f1_score'] = 2 * (precision * recall) \\\n",
        "        / ((precision + recall) or 1)\n",
        "\n",
        "    log.info((\"E{} {:8} \"\n",
        "              + \"{loss/all:.4f} loss, \"\n",
        "              + \"{pr/precision:.4f} precision, \"\n",
        "              + \"{pr/recall:.4f} recall, \"\n",
        "              + \"{pr/f1_score:.4f} f1 score\"\n",
        "              ).format(\n",
        "        epoch_ndx,\n",
        "        mode_str,\n",
        "        **metrics_dict,\n",
        "    ))\n",
        "    log.info((\"E{} {:8} \"\n",
        "              + \"{loss/all:.4f} loss, \"\n",
        "              + \"{percent_all/tp:-5.1f}% tp, {percent_all/fn:-5.1f}% fn, {percent_all/fp:-9.1f}% fp\"\n",
        "    ).format(\n",
        "        epoch_ndx,\n",
        "        mode_str + '_all',\n",
        "        **metrics_dict,\n",
        "    ))\n",
        "    global trn_writer\n",
        "    global val_writer\n",
        "    initTensorboardWriters()\n",
        "    if mode_str == 'trn':\n",
        "      writer = trn_writer\n",
        "    elif mode_str == 'pred':\n",
        "      writer = pred_writer\n",
        "    else:\n",
        "      writer = val_writer\n",
        "\n",
        "    prefix_str = 'seg_'\n",
        "\n",
        "    global totalTrainingSamples_count\n",
        "    for key, value in metrics_dict.items():\n",
        "        writer.add_scalar(prefix_str + key, value, totalTrainingSamples_count)\n",
        "\n",
        "    writer.flush()\n",
        "\n",
        "    score = metrics_dict['pr/recall']\n",
        "\n",
        "    return score\n",
        "\n",
        "import os\n",
        "\n",
        "LOG_DIR = os.path.join(BASE_DIR, 'logs')\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.mkdir(LOG_DIR)\n",
        "  \n",
        "def initTensorboardWriters():\n",
        "    global trn_writer\n",
        "    global val_writer\n",
        "    global pred_writer\n",
        "    if trn_writer is None:\n",
        "        trn_writer = SummaryWriter(\n",
        "            log_dir= os.path.join(LOG_DIR, '{}_trn_seg_{}').format(TB_PREFIX, time_str) )\n",
        "        val_writer = SummaryWriter(\n",
        "            log_dir= os.path.join(LOG_DIR, '{}_val_seg_{}').format(TB_PREFIX, time_str) )\n",
        "#         pred_writer = SummaryWriter(\n",
        "#             log_dir= os.path.join(LOG_DIR, '{}_pred_seg_{}').format(TB_PREFIX, time_str) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vH1XOnNUHGJn"
      },
      "outputs": [],
      "source": [
        "def saveModel(type_str, epoch_ndx, tb_pre = TB_PREFIX):\n",
        "    model_name = '{}_model_epoch{}'.format(tb_pre, epoch_ndx)\n",
        "    file_path = os.path.join(\n",
        "        BASE_DIR,\n",
        "        'models',\n",
        "        model_name\n",
        "        )\n",
        "\n",
        "    os.makedirs(os.path.dirname(file_path), mode=0o755, exist_ok=True)\n",
        "\n",
        "    model = segmentation_model\n",
        "    if isinstance(model, torch.nn.DataParallel):\n",
        "        model = model.module\n",
        "\n",
        "    state = {\n",
        "        'sys_argv': sys.argv,\n",
        "        'time': str(datetime.datetime.now()),\n",
        "        'model_state': model.state_dict(),\n",
        "        'model_name': type(model).__name__,\n",
        "        'optimizer_state' : optimizer.state_dict(),\n",
        "        'optimizer_name': type(optimizer).__name__,\n",
        "        'epoch': epoch_ndx,\n",
        "        'totalTrainingSamples_count': totalTrainingSamples_count,\n",
        "    }\n",
        "    torch.save(state, file_path)\n",
        "    log.info(f\"Model was saved to {file_path}\")\n",
        "#     remote_location = 's3://{0}'.format(os.path.join(s3bucket, 'result/models', model_name))\n",
        "#     S3FS.put(file_path, remote_location)\n",
        "#     log.info(\"Saved model params to {} and remote S3 bucket\".format(file_path))\n",
        "\n",
        "    with open(file_path, 'rb') as f:\n",
        "        log.info(\"SHA1: \" + hashlib.sha1(f.read()).hexdigest())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "2b5xrob-nmpP"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Pytorch 3D image tensor = Depth, Height, Weight\n",
        "#w(l-> r), h(t->b), d(u->d) 순서로군\n",
        "\n",
        "def pad_for_division(image, patch_size):\n",
        "    patch_d, patch_h, patch_w = patch_size \n",
        "    assert patch_d % 32 == 0 & patch_h % 32 == 0 & patch_w % 32 == 0, \"Patch size should be divided by 32\"\n",
        "    padding_d = patch_d - image.size(0)%patch_d\n",
        "    padding_h = patch_h - image.size(1)%patch_h\n",
        "    padding_w = patch_w - image.size(2)%patch_w\n",
        "    padded_image = F.pad(image, (0, padding_w, 0, padding_h, 0, padding_d))\n",
        "    return padded_image \n",
        "\n",
        "def pad_for_half(image, patch_size):\n",
        "    patch_d, patch_h, patch_w = patch_size \n",
        "    padded_image = F.pad(image, (patch_w//2, patch_w//2, patch_h//2, patch_h//2, patch_d//2, patch_d//2))\n",
        "    return padded_image \n",
        "\n",
        "    \n",
        "def adjust_window(image, window):\n",
        "    width = window[0]\n",
        "    level = window[1]\n",
        "    upper = level+width/2\n",
        "    lower = level-width/2\n",
        "    copied_image = image.clip(lower, upper)\n",
        "    copied_image = copied_image-lower\n",
        "    return (copied_image/(upper-lower))\n",
        "\n",
        "def convert_to_multi_channel_img(image, windows):\n",
        "    adjusted_images = [adjust_window(image, window) for window in windows]\n",
        "    return torch.stack(adjusted_images)\n",
        "\n",
        "# Process : padding -> adjust windows -> unfold -> neural network -> fold -> crop\n",
        "#           another padding -> adjust windows -> unfold -> neural network -> fold -> crop \n",
        "#           average all by 2 -> compare with the label. \n",
        "# 원래는 8개로 해야되는데, 간이 버전이라고 생각해볼 수 있겠음. \n",
        "\n",
        "def pred_image_with_model(padded_image, model, batch_size, patch_size):\n",
        "    '''\n",
        "    padded_image : image tensor with size of [D, H, W]\n",
        "    patch_size : tuple with size of 3\n",
        "    return pred_label : tensor with size of [D, H, W]\n",
        "    '''\n",
        "    windows = [(500,200), (700,400), (1200,400)]\n",
        "    input_channel = padded_image.size(0)\n",
        "    output_channel = 1\n",
        "    patch_d, patch_h, patch_w = patch_size \n",
        "    total_batch_size = batch_size * torch.cuda.device_count()\n",
        "\n",
        "    patches = padded_image.unfold(0, patch_d, patch_d).unfold(1, patch_h, patch_h).unfold(2, patch_w, patch_w)\n",
        "    unfold_shape = patches.size()\n",
        "    patches = patches.reshape(-1, patch_d, patch_h, patch_w)\n",
        "    \n",
        "    processed_patches = torch.zeros_like(patches)\n",
        "    iter_num = int(np.ceil(patches.size(0)/total_batch_size))\n",
        "    for i in range(iter_num):\n",
        "        start = i * total_batch_size\n",
        "        end = (i+1) * total_batch_size\n",
        "        batch = patches[start:end]\n",
        "        batch = convert_to_multi_channel_img(batch, windows)\n",
        "        batch = batch.permute(1,0,2,3,4)\n",
        "        proccessed_batch = model(batch).squeeze(1)\n",
        "        processed_patches[start:end] = proccessed_batch\n",
        "    \n",
        "    pred_patches = processed_patches.view(unfold_shape)\n",
        "    output_d = unfold_shape[0] * unfold_shape[3]\n",
        "    output_h = unfold_shape[1] * unfold_shape[4]\n",
        "    output_w = unfold_shape[2] * unfold_shape[5]\n",
        "    pred_patches = pred_patches.permute(0, 3, 1, 4, 2, 5)\n",
        "    pred_label = pred_patches.reshape(output_d, output_h, output_w)\n",
        "    return pred_label\n",
        "\n",
        "def predict_one_case(image_t, batch_size ,patch_size):\n",
        "    pad_image = pad_for_division(image_t, patch_size)\n",
        "    half_pad_image = pad_for_half(pad_image, patch_size)\n",
        "    d,h,w = image_t.shape\n",
        "    half_pad_d, half_pad_h, half_pad_w = [size//2 for size in patch_size]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        segmentation_model.eval()\n",
        "        pred_label = pred_image_with_model(pad_image, segmentation_model, batch_size, patch_size)\n",
        "        pred_half_pad_label = pred_image_with_model(half_pad_image, segmentation_model, batch_size, patch_size)\n",
        "        \n",
        "    cropped_pred = pred_label[:d, :h, :w]\n",
        "    cropped_pred_2 = pred_half_pad_label[half_pad_d:half_pad_d+d, half_pad_h:half_pad_h+h, half_pad_w:half_pad_w+w]\n",
        "    mean_pred = (cropped_pred + cropped_pred_2) / 2\n",
        "    return mean_pred\n",
        "\n",
        "\n",
        "def doPrediction(epoch_ndx, files, batch_size, patch_size):\n",
        "    log.info(\"E{} Prediction {}\".format(epoch_ndx, TB_PREFIX))\n",
        "    predMetrics_g = torch.zeros(METRICS_SIZE, len(files), device=DEVICE)\n",
        "    segmentation_model.eval()\n",
        "    \n",
        "    for i, file in enumerate(files):\n",
        "        image = np.load(get_img_path(file))\n",
        "        image_t = torch.tensor(image)\n",
        "        label = np.load(get_label_path(file))\n",
        "        \n",
        "        pred = predict_one_case(image_t, batch_size, patch_size)\n",
        "        pred_t = pred > 0.5 # classificationThreshold = 0.5\n",
        "        label_t = torch.tensor(label)\n",
        "        \n",
        "        predictionBool_g = pred_t.unsqueeze(0).to(torch.float32)\n",
        "        label_g = label_t.unsqueeze(0)\n",
        "        \n",
        "        diceLoss_g = diceLoss(predictionBool_g, label_g, epsilon=0.01)\n",
        "        fnLoss_g = diceLoss(predictionBool_g * label_g, label_g)\n",
        "\n",
        "        tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3])\n",
        "        fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3])\n",
        "        fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3])\n",
        "        \n",
        "        predMetrics_g[METRICS_LOSS_NDX, i] = diceLoss_g # 차원 에러날듯 - i로 골라버리면 차원이 하나 줄기 때문.. 확인해봐야함. \n",
        "        predMetrics_g[METRICS_TP_NDX, i] = tp\n",
        "        predMetrics_g[METRICS_FN_NDX, i] = fn\n",
        "        predMetrics_g[METRICS_FP_NDX, i] = fp\n",
        "        \n",
        "    return predMetrics_g.to('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xamjgc4JFgtg"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr_7sXmynmpP",
        "outputId": "e511db21-21e0-44e0-fc6a-bc585b3f578a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-04 05:49:32,574 INFO     pid:15041 3DUnet:001:<module> Starting traning...\n"
          ]
        }
      ],
      "source": [
        "log.info(\"Starting traning...\")\n",
        "\n",
        "train_dl = initTrainDl(train_dataset)\n",
        "val_dl = initValDl(val_dataset)\n",
        "\n",
        "best_score = 0.0\n",
        "validation_cadence = 10\n",
        "\n",
        "totalTrainingSamples_count = 0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-cNzCU0nmpP",
        "outputId": "11212cf7-0755-49c4-e8a2-cf01d9a84a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-04 05:49:33,240 INFO     pid:15041 3DUnet:002:<module> Epoch 1 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:49:33,246 WARNING  pid:15041 util.util:219:enumerateWithEstimate E1 Training ----/23, starting\n",
            "2023-02-04 05:49:56,276 INFO     pid:15041 util.util:236:enumerateWithEstimate E1 Training    4/23, done at 2023-02-04 05:50:49, 0:01:01\n",
            "2023-02-04 05:50:08,173 INFO     pid:15041 util.util:236:enumerateWithEstimate E1 Training    8/23, done at 2023-02-04 05:50:49, 0:01:02\n",
            "2023-02-04 05:50:32,232 INFO     pid:15041 util.util:236:enumerateWithEstimate E1 Training   16/23, done at 2023-02-04 05:50:50, 0:01:02\n",
            "2023-02-04 05:50:49,115 WARNING  pid:15041 util.util:249:enumerateWithEstimate E1 Training ----/23, done at 2023-02-04 05:50:49\n",
            "2023-02-04 05:50:49,118 INFO     pid:15041 3DUnet:004:logMetrics E1 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:50:49,121 INFO     pid:15041 3DUnet:035:logMetrics E1 trn      0.7710 loss, 0.0508 precision, 0.6482 recall, 0.0941 f1 score\n",
            "2023-02-04 05:50:49,124 INFO     pid:15041 3DUnet:045:logMetrics E1 trn_all  0.7710 loss,  64.8% tp,  35.2% fn,    1212.2% fp\n",
            "2023-02-04 05:50:53,806 WARNING  pid:15041 util.util:219:enumerateWithEstimate E1 Validation  ----/3, starting\n",
            "2023-02-04 05:50:54,227 WARNING  pid:15041 util.util:249:enumerateWithEstimate E1 Validation  ----/3, done at 2023-02-04 05:50:54\n",
            "2023-02-04 05:50:56,128 INFO     pid:15041 3DUnet:004:logMetrics E1 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:50:56,131 INFO     pid:15041 3DUnet:035:logMetrics E1 val      0.6241 loss, 0.0280 precision, 0.6195 recall, 0.0536 f1 score\n",
            "2023-02-04 05:50:56,134 INFO     pid:15041 3DUnet:045:logMetrics E1 val_all  0.6241 loss,  62.0% tp,  38.0% fn,    2149.7% fp\n",
            "2023-02-04 05:50:57,085 INFO     pid:15041 3DUnet:026:saveModel Model was saved to /gdrive/MyDrive/LiTS_sample/models/bonemeta_fn_0_3D_Unet_DropRes_lv5_All128_model_epoch1\n",
            "2023-02-04 05:50:57,674 INFO     pid:15041 3DUnet:032:saveModel SHA1: bdf2c7d7d1a87a641314425f9f798bb5f1f73f29\n",
            "2023-02-04 05:50:57,677 INFO     pid:15041 3DUnet:002:<module> Epoch 2 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:50:57,680 WARNING  pid:15041 util.util:219:enumerateWithEstimate E2 Training ----/23, starting\n",
            "2023-02-04 05:51:14,400 INFO     pid:15041 util.util:236:enumerateWithEstimate E2 Training    4/23, done at 2023-02-04 05:52:09, 0:01:04\n",
            "2023-02-04 05:51:26,793 INFO     pid:15041 util.util:236:enumerateWithEstimate E2 Training    8/23, done at 2023-02-04 05:52:10, 0:01:04\n",
            "2023-02-04 05:51:51,535 INFO     pid:15041 util.util:236:enumerateWithEstimate E2 Training   16/23, done at 2023-02-04 05:52:10, 0:01:04\n",
            "2023-02-04 05:52:08,776 WARNING  pid:15041 util.util:249:enumerateWithEstimate E2 Training ----/23, done at 2023-02-04 05:52:08\n",
            "2023-02-04 05:52:08,781 INFO     pid:15041 3DUnet:004:logMetrics E2 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:52:08,784 INFO     pid:15041 3DUnet:035:logMetrics E2 trn      0.4619 loss, 0.0555 precision, 0.6630 recall, 0.1025 f1 score\n",
            "2023-02-04 05:52:08,787 INFO     pid:15041 3DUnet:045:logMetrics E2 trn_all  0.4619 loss,  66.3% tp,  33.7% fn,    1127.4% fp\n",
            "2023-02-04 05:52:08,791 INFO     pid:15041 3DUnet:002:<module> Epoch 3 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:52:08,795 WARNING  pid:15041 util.util:219:enumerateWithEstimate E3 Training ----/23, starting\n",
            "2023-02-04 05:52:25,611 INFO     pid:15041 util.util:236:enumerateWithEstimate E3 Training    4/23, done at 2023-02-04 05:53:21, 0:01:05\n",
            "2023-02-04 05:52:38,170 INFO     pid:15041 util.util:236:enumerateWithEstimate E3 Training    8/23, done at 2023-02-04 05:53:22, 0:01:05\n",
            "2023-02-04 05:53:03,436 INFO     pid:15041 util.util:236:enumerateWithEstimate E3 Training   16/23, done at 2023-02-04 05:53:22, 0:01:06\n",
            "2023-02-04 05:53:21,103 WARNING  pid:15041 util.util:249:enumerateWithEstimate E3 Training ----/23, done at 2023-02-04 05:53:21\n",
            "2023-02-04 05:53:21,109 INFO     pid:15041 3DUnet:004:logMetrics E3 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:53:21,110 INFO     pid:15041 3DUnet:035:logMetrics E3 trn      0.3198 loss, 0.0498 precision, 0.6007 recall, 0.0920 f1 score\n",
            "2023-02-04 05:53:21,112 INFO     pid:15041 3DUnet:045:logMetrics E3 trn_all  0.3198 loss,  60.1% tp,  39.9% fn,    1145.2% fp\n",
            "2023-02-04 05:53:21,119 INFO     pid:15041 3DUnet:002:<module> Epoch 4 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:53:21,124 WARNING  pid:15041 util.util:219:enumerateWithEstimate E4 Training ----/23, starting\n",
            "2023-02-04 05:53:38,399 INFO     pid:15041 util.util:236:enumerateWithEstimate E4 Training    4/23, done at 2023-02-04 05:54:36, 0:01:07\n",
            "2023-02-04 05:53:51,074 INFO     pid:15041 util.util:236:enumerateWithEstimate E4 Training    8/23, done at 2023-02-04 05:54:35, 0:01:06\n",
            "2023-02-04 05:54:16,511 INFO     pid:15041 util.util:236:enumerateWithEstimate E4 Training   16/23, done at 2023-02-04 05:54:35, 0:01:06\n",
            "2023-02-04 05:54:34,396 WARNING  pid:15041 util.util:249:enumerateWithEstimate E4 Training ----/23, done at 2023-02-04 05:54:34\n",
            "2023-02-04 05:54:34,400 INFO     pid:15041 3DUnet:004:logMetrics E4 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:54:34,403 INFO     pid:15041 3DUnet:035:logMetrics E4 trn      0.2788 loss, 0.0484 precision, 0.5616 recall, 0.0892 f1 score\n",
            "2023-02-04 05:54:34,405 INFO     pid:15041 3DUnet:045:logMetrics E4 trn_all  0.2788 loss,  56.2% tp,  43.8% fn,    1103.4% fp\n",
            "2023-02-04 05:54:34,410 INFO     pid:15041 3DUnet:002:<module> Epoch 5 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:54:34,413 WARNING  pid:15041 util.util:219:enumerateWithEstimate E5 Training ----/23, starting\n",
            "2023-02-04 05:54:51,617 INFO     pid:15041 util.util:236:enumerateWithEstimate E5 Training    4/23, done at 2023-02-04 05:55:49, 0:01:07\n",
            "2023-02-04 05:55:04,434 INFO     pid:15041 util.util:236:enumerateWithEstimate E5 Training    8/23, done at 2023-02-04 05:55:49, 0:01:07\n",
            "2023-02-04 05:55:29,829 INFO     pid:15041 util.util:236:enumerateWithEstimate E5 Training   16/23, done at 2023-02-04 05:55:48, 0:01:06\n",
            "2023-02-04 05:55:47,534 WARNING  pid:15041 util.util:249:enumerateWithEstimate E5 Training ----/23, done at 2023-02-04 05:55:47\n",
            "2023-02-04 05:55:47,537 INFO     pid:15041 3DUnet:004:logMetrics E5 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:55:47,539 INFO     pid:15041 3DUnet:035:logMetrics E5 trn      0.2358 loss, 0.0459 precision, 0.5392 recall, 0.0846 f1 score\n",
            "2023-02-04 05:55:47,541 INFO     pid:15041 3DUnet:045:logMetrics E5 trn_all  0.2358 loss,  53.9% tp,  46.1% fn,    1120.1% fp\n",
            "2023-02-04 05:55:47,544 INFO     pid:15041 3DUnet:002:<module> Epoch 6 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:55:47,546 WARNING  pid:15041 util.util:219:enumerateWithEstimate E6 Training ----/23, starting\n",
            "2023-02-04 05:56:04,785 INFO     pid:15041 util.util:236:enumerateWithEstimate E6 Training    4/23, done at 2023-02-04 05:57:02, 0:01:07\n",
            "2023-02-04 05:56:17,580 INFO     pid:15041 util.util:236:enumerateWithEstimate E6 Training    8/23, done at 2023-02-04 05:57:02, 0:01:07\n",
            "2023-02-04 05:56:43,056 INFO     pid:15041 util.util:236:enumerateWithEstimate E6 Training   16/23, done at 2023-02-04 05:57:02, 0:01:07\n",
            "2023-02-04 05:57:00,776 WARNING  pid:15041 util.util:249:enumerateWithEstimate E6 Training ----/23, done at 2023-02-04 05:57:00\n",
            "2023-02-04 05:57:00,779 INFO     pid:15041 3DUnet:004:logMetrics E6 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:57:00,782 INFO     pid:15041 3DUnet:035:logMetrics E6 trn      0.1910 loss, 0.0428 precision, 0.5328 recall, 0.0793 f1 score\n",
            "2023-02-04 05:57:00,783 INFO     pid:15041 3DUnet:045:logMetrics E6 trn_all  0.1910 loss,  53.3% tp,  46.7% fn,    1191.0% fp\n",
            "2023-02-04 05:57:00,787 INFO     pid:15041 3DUnet:002:<module> Epoch 7 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:57:00,790 WARNING  pid:15041 util.util:219:enumerateWithEstimate E7 Training ----/23, starting\n",
            "2023-02-04 05:57:17,854 INFO     pid:15041 util.util:236:enumerateWithEstimate E7 Training    4/23, done at 2023-02-04 05:58:15, 0:01:06\n",
            "2023-02-04 05:57:30,614 INFO     pid:15041 util.util:236:enumerateWithEstimate E7 Training    8/23, done at 2023-02-04 05:58:15, 0:01:06\n",
            "2023-02-04 05:57:56,281 INFO     pid:15041 util.util:236:enumerateWithEstimate E7 Training   16/23, done at 2023-02-04 05:58:15, 0:01:07\n",
            "2023-02-04 05:58:14,086 WARNING  pid:15041 util.util:249:enumerateWithEstimate E7 Training ----/23, done at 2023-02-04 05:58:14\n",
            "2023-02-04 05:58:14,088 INFO     pid:15041 3DUnet:004:logMetrics E7 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:58:14,097 INFO     pid:15041 3DUnet:035:logMetrics E7 trn      0.1919 loss, 0.0430 precision, 0.5245 recall, 0.0795 f1 score\n",
            "2023-02-04 05:58:14,099 INFO     pid:15041 3DUnet:045:logMetrics E7 trn_all  0.1919 loss,  52.4% tp,  47.6% fn,    1167.0% fp\n",
            "2023-02-04 05:58:14,105 INFO     pid:15041 3DUnet:002:<module> Epoch 8 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:58:14,107 WARNING  pid:15041 util.util:219:enumerateWithEstimate E8 Training ----/23, starting\n",
            "2023-02-04 05:58:31,283 INFO     pid:15041 util.util:236:enumerateWithEstimate E8 Training    4/23, done at 2023-02-04 05:59:28, 0:01:07\n",
            "2023-02-04 05:58:44,033 INFO     pid:15041 util.util:236:enumerateWithEstimate E8 Training    8/23, done at 2023-02-04 05:59:28, 0:01:07\n",
            "2023-02-04 05:59:09,637 INFO     pid:15041 util.util:236:enumerateWithEstimate E8 Training   16/23, done at 2023-02-04 05:59:28, 0:01:07\n",
            "2023-02-04 05:59:27,468 WARNING  pid:15041 util.util:249:enumerateWithEstimate E8 Training ----/23, done at 2023-02-04 05:59:27\n",
            "2023-02-04 05:59:27,469 INFO     pid:15041 3DUnet:004:logMetrics E8 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 05:59:27,474 INFO     pid:15041 3DUnet:035:logMetrics E8 trn      0.1896 loss, 0.0416 precision, 0.5218 recall, 0.0771 f1 score\n",
            "2023-02-04 05:59:27,476 INFO     pid:15041 3DUnet:045:logMetrics E8 trn_all  0.1896 loss,  52.2% tp,  47.8% fn,    1201.8% fp\n",
            "2023-02-04 05:59:27,482 INFO     pid:15041 3DUnet:002:<module> Epoch 9 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 05:59:27,485 WARNING  pid:15041 util.util:219:enumerateWithEstimate E9 Training ----/23, starting\n",
            "2023-02-04 05:59:44,641 INFO     pid:15041 util.util:236:enumerateWithEstimate E9 Training    4/23, done at 2023-02-04 06:00:41, 0:01:06\n",
            "2023-02-04 05:59:57,345 INFO     pid:15041 util.util:236:enumerateWithEstimate E9 Training    8/23, done at 2023-02-04 06:00:41, 0:01:06\n",
            "2023-02-04 06:00:22,768 INFO     pid:15041 util.util:236:enumerateWithEstimate E9 Training   16/23, done at 2023-02-04 06:00:41, 0:01:06\n",
            "2023-02-04 06:00:40,508 WARNING  pid:15041 util.util:249:enumerateWithEstimate E9 Training ----/23, done at 2023-02-04 06:00:40\n",
            "2023-02-04 06:00:40,514 INFO     pid:15041 3DUnet:004:logMetrics E9 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:00:40,516 INFO     pid:15041 3DUnet:035:logMetrics E9 trn      0.1902 loss, 0.0412 precision, 0.5168 recall, 0.0763 f1 score\n",
            "2023-02-04 06:00:40,518 INFO     pid:15041 3DUnet:045:logMetrics E9 trn_all  0.1902 loss,  51.7% tp,  48.3% fn,    1202.6% fp\n",
            "2023-02-04 06:00:40,521 INFO     pid:15041 3DUnet:002:<module> Epoch 10 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:00:40,523 WARNING  pid:15041 util.util:219:enumerateWithEstimate E10 Training ----/23, starting\n",
            "2023-02-04 06:00:57,762 INFO     pid:15041 util.util:236:enumerateWithEstimate E10 Training    4/23, done at 2023-02-04 06:01:55, 0:01:07\n",
            "2023-02-04 06:01:10,510 INFO     pid:15041 util.util:236:enumerateWithEstimate E10 Training    8/23, done at 2023-02-04 06:01:55, 0:01:07\n",
            "2023-02-04 06:01:35,985 INFO     pid:15041 util.util:236:enumerateWithEstimate E10 Training   16/23, done at 2023-02-04 06:01:55, 0:01:06\n",
            "2023-02-04 06:01:53,772 WARNING  pid:15041 util.util:249:enumerateWithEstimate E10 Training ----/23, done at 2023-02-04 06:01:53\n",
            "2023-02-04 06:01:53,774 INFO     pid:15041 3DUnet:004:logMetrics E10 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:01:53,780 INFO     pid:15041 3DUnet:035:logMetrics E10 trn      0.1491 loss, 0.0402 precision, 0.5164 recall, 0.0746 f1 score\n",
            "2023-02-04 06:01:53,782 INFO     pid:15041 3DUnet:045:logMetrics E10 trn_all  0.1491 loss,  51.6% tp,  48.4% fn,    1232.8% fp\n",
            "2023-02-04 06:01:53,789 WARNING  pid:15041 util.util:219:enumerateWithEstimate E10 Validation  ----/3, starting\n",
            "2023-02-04 06:01:54,231 WARNING  pid:15041 util.util:249:enumerateWithEstimate E10 Validation  ----/3, done at 2023-02-04 06:01:54\n",
            "2023-02-04 06:01:56,237 INFO     pid:15041 3DUnet:004:logMetrics E10 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:01:56,239 INFO     pid:15041 3DUnet:035:logMetrics E10 val      0.2320 loss, 0.0235 precision, 0.5032 recall, 0.0449 f1 score\n",
            "2023-02-04 06:01:56,241 INFO     pid:15041 3DUnet:045:logMetrics E10 val_all  0.2320 loss,  50.3% tp,  49.7% fn,    2089.4% fp\n",
            "2023-02-04 06:01:56,958 INFO     pid:15041 3DUnet:026:saveModel Model was saved to /gdrive/MyDrive/LiTS_sample/models/bonemeta_fn_0_3D_Unet_DropRes_lv5_All128_model_epoch10\n",
            "2023-02-04 06:01:57,492 INFO     pid:15041 3DUnet:032:saveModel SHA1: 584e7bed7c27b8196703d667ea6cac6e060e8886\n",
            "2023-02-04 06:01:57,493 INFO     pid:15041 3DUnet:002:<module> Epoch 11 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:01:57,498 WARNING  pid:15041 util.util:219:enumerateWithEstimate E11 Training ----/23, starting\n",
            "2023-02-04 06:02:14,836 INFO     pid:15041 util.util:236:enumerateWithEstimate E11 Training    4/23, done at 2023-02-04 06:03:12, 0:01:07\n",
            "2023-02-04 06:02:27,606 INFO     pid:15041 util.util:236:enumerateWithEstimate E11 Training    8/23, done at 2023-02-04 06:03:12, 0:01:07\n",
            "2023-02-04 06:02:53,209 INFO     pid:15041 util.util:236:enumerateWithEstimate E11 Training   16/23, done at 2023-02-04 06:03:12, 0:01:07\n",
            "2023-02-04 06:03:10,995 WARNING  pid:15041 util.util:249:enumerateWithEstimate E11 Training ----/23, done at 2023-02-04 06:03:10\n",
            "2023-02-04 06:03:11,000 INFO     pid:15041 3DUnet:004:logMetrics E11 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:03:11,002 INFO     pid:15041 3DUnet:035:logMetrics E11 trn      0.1748 loss, 0.0436 precision, 0.5157 recall, 0.0805 f1 score\n",
            "2023-02-04 06:03:11,004 INFO     pid:15041 3DUnet:045:logMetrics E11 trn_all  0.1748 loss,  51.6% tp,  48.4% fn,    1130.4% fp\n",
            "2023-02-04 06:03:11,009 INFO     pid:15041 3DUnet:002:<module> Epoch 12 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:03:11,014 WARNING  pid:15041 util.util:219:enumerateWithEstimate E12 Training ----/23, starting\n",
            "2023-02-04 06:03:28,162 INFO     pid:15041 util.util:236:enumerateWithEstimate E12 Training    4/23, done at 2023-02-04 06:04:25, 0:01:07\n",
            "2023-02-04 06:03:41,052 INFO     pid:15041 util.util:236:enumerateWithEstimate E12 Training    8/23, done at 2023-02-04 06:04:25, 0:01:07\n",
            "2023-02-04 06:04:06,654 INFO     pid:15041 util.util:236:enumerateWithEstimate E12 Training   16/23, done at 2023-02-04 06:04:25, 0:01:07\n",
            "2023-02-04 06:04:24,474 WARNING  pid:15041 util.util:249:enumerateWithEstimate E12 Training ----/23, done at 2023-02-04 06:04:24\n",
            "2023-02-04 06:04:24,476 INFO     pid:15041 3DUnet:004:logMetrics E12 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:04:24,479 INFO     pid:15041 3DUnet:035:logMetrics E12 trn      0.1519 loss, 0.0416 precision, 0.5146 recall, 0.0769 f1 score\n",
            "2023-02-04 06:04:24,481 INFO     pid:15041 3DUnet:045:logMetrics E12 trn_all  0.1519 loss,  51.5% tp,  48.5% fn,    1186.8% fp\n",
            "2023-02-04 06:04:24,483 INFO     pid:15041 3DUnet:002:<module> Epoch 13 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:04:24,485 WARNING  pid:15041 util.util:219:enumerateWithEstimate E13 Training ----/23, starting\n",
            "2023-02-04 06:04:41,542 INFO     pid:15041 util.util:236:enumerateWithEstimate E13 Training    4/23, done at 2023-02-04 06:05:38, 0:01:06\n",
            "2023-02-04 06:04:54,416 INFO     pid:15041 util.util:236:enumerateWithEstimate E13 Training    8/23, done at 2023-02-04 06:05:39, 0:01:07\n",
            "2023-02-04 06:05:19,929 INFO     pid:15041 util.util:236:enumerateWithEstimate E13 Training   16/23, done at 2023-02-04 06:05:39, 0:01:06\n",
            "2023-02-04 06:05:37,663 WARNING  pid:15041 util.util:249:enumerateWithEstimate E13 Training ----/23, done at 2023-02-04 06:05:37\n",
            "2023-02-04 06:05:37,665 INFO     pid:15041 3DUnet:004:logMetrics E13 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:05:37,667 INFO     pid:15041 3DUnet:035:logMetrics E13 trn      0.1238 loss, 0.0392 precision, 0.5134 recall, 0.0729 f1 score\n",
            "2023-02-04 06:05:37,668 INFO     pid:15041 3DUnet:045:logMetrics E13 trn_all  0.1238 loss,  51.3% tp,  48.7% fn,    1256.9% fp\n",
            "2023-02-04 06:05:37,671 INFO     pid:15041 3DUnet:002:<module> Epoch 14 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:05:37,674 WARNING  pid:15041 util.util:219:enumerateWithEstimate E14 Training ----/23, starting\n",
            "2023-02-04 06:05:54,870 INFO     pid:15041 util.util:236:enumerateWithEstimate E14 Training    4/23, done at 2023-02-04 06:06:52, 0:01:07\n",
            "2023-02-04 06:06:07,669 INFO     pid:15041 util.util:236:enumerateWithEstimate E14 Training    8/23, done at 2023-02-04 06:06:52, 0:01:07\n",
            "2023-02-04 06:06:33,251 INFO     pid:15041 util.util:236:enumerateWithEstimate E14 Training   16/23, done at 2023-02-04 06:06:52, 0:01:07\n",
            "2023-02-04 06:06:51,069 WARNING  pid:15041 util.util:249:enumerateWithEstimate E14 Training ----/23, done at 2023-02-04 06:06:51\n",
            "2023-02-04 06:06:51,071 INFO     pid:15041 3DUnet:004:logMetrics E14 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:06:51,075 INFO     pid:15041 3DUnet:035:logMetrics E14 trn      0.1181 loss, 0.0417 precision, 0.5118 recall, 0.0771 f1 score\n",
            "2023-02-04 06:06:51,078 INFO     pid:15041 3DUnet:045:logMetrics E14 trn_all  0.1181 loss,  51.2% tp,  48.8% fn,    1176.3% fp\n",
            "2023-02-04 06:06:51,083 INFO     pid:15041 3DUnet:002:<module> Epoch 15 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:06:51,090 WARNING  pid:15041 util.util:219:enumerateWithEstimate E15 Training ----/23, starting\n",
            "2023-02-04 06:07:08,317 INFO     pid:15041 util.util:236:enumerateWithEstimate E15 Training    4/23, done at 2023-02-04 06:08:05, 0:01:07\n",
            "2023-02-04 06:07:21,106 INFO     pid:15041 util.util:236:enumerateWithEstimate E15 Training    8/23, done at 2023-02-04 06:08:05, 0:01:07\n",
            "2023-02-04 06:07:46,718 INFO     pid:15041 util.util:236:enumerateWithEstimate E15 Training   16/23, done at 2023-02-04 06:08:05, 0:01:07\n",
            "2023-02-04 06:08:04,613 WARNING  pid:15041 util.util:249:enumerateWithEstimate E15 Training ----/23, done at 2023-02-04 06:08:04\n",
            "2023-02-04 06:08:04,619 INFO     pid:15041 3DUnet:004:logMetrics E15 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:08:04,620 INFO     pid:15041 3DUnet:035:logMetrics E15 trn      0.1343 loss, 0.0393 precision, 0.5100 recall, 0.0730 f1 score\n",
            "2023-02-04 06:08:04,622 INFO     pid:15041 3DUnet:045:logMetrics E15 trn_all  0.1343 loss,  51.0% tp,  49.0% fn,    1247.2% fp\n",
            "2023-02-04 06:08:04,628 INFO     pid:15041 3DUnet:002:<module> Epoch 16 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:08:04,631 WARNING  pid:15041 util.util:219:enumerateWithEstimate E16 Training ----/23, starting\n",
            "2023-02-04 06:08:21,843 INFO     pid:15041 util.util:236:enumerateWithEstimate E16 Training    4/23, done at 2023-02-04 06:09:19, 0:01:07\n",
            "2023-02-04 06:08:34,540 INFO     pid:15041 util.util:236:enumerateWithEstimate E16 Training    8/23, done at 2023-02-04 06:09:19, 0:01:06\n",
            "2023-02-04 06:09:00,053 INFO     pid:15041 util.util:236:enumerateWithEstimate E16 Training   16/23, done at 2023-02-04 06:09:19, 0:01:06\n",
            "2023-02-04 06:09:17,746 WARNING  pid:15041 util.util:249:enumerateWithEstimate E16 Training ----/23, done at 2023-02-04 06:09:17\n",
            "2023-02-04 06:09:17,749 INFO     pid:15041 3DUnet:004:logMetrics E16 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:09:17,754 INFO     pid:15041 3DUnet:035:logMetrics E16 trn      0.1196 loss, 0.0428 precision, 0.5100 recall, 0.0789 f1 score\n",
            "2023-02-04 06:09:17,755 INFO     pid:15041 3DUnet:045:logMetrics E16 trn_all  0.1196 loss,  51.0% tp,  49.0% fn,    1141.3% fp\n",
            "2023-02-04 06:09:17,759 INFO     pid:15041 3DUnet:002:<module> Epoch 17 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:09:17,762 WARNING  pid:15041 util.util:219:enumerateWithEstimate E17 Training ----/23, starting\n",
            "2023-02-04 06:09:35,003 INFO     pid:15041 util.util:236:enumerateWithEstimate E17 Training    4/23, done at 2023-02-04 06:10:32, 0:01:07\n",
            "2023-02-04 06:09:47,874 INFO     pid:15041 util.util:236:enumerateWithEstimate E17 Training    8/23, done at 2023-02-04 06:10:32, 0:01:07\n",
            "2023-02-04 06:10:13,294 INFO     pid:15041 util.util:236:enumerateWithEstimate E17 Training   16/23, done at 2023-02-04 06:10:32, 0:01:07\n",
            "2023-02-04 06:10:31,027 WARNING  pid:15041 util.util:249:enumerateWithEstimate E17 Training ----/23, done at 2023-02-04 06:10:31\n",
            "2023-02-04 06:10:31,032 INFO     pid:15041 3DUnet:004:logMetrics E17 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:10:31,035 INFO     pid:15041 3DUnet:035:logMetrics E17 trn      0.1258 loss, 0.0393 precision, 0.5089 recall, 0.0729 f1 score\n",
            "2023-02-04 06:10:31,036 INFO     pid:15041 3DUnet:045:logMetrics E17 trn_all  0.1258 loss,  50.9% tp,  49.1% fn,    1245.1% fp\n",
            "2023-02-04 06:10:31,039 INFO     pid:15041 3DUnet:002:<module> Epoch 18 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:10:31,043 WARNING  pid:15041 util.util:219:enumerateWithEstimate E18 Training ----/23, starting\n",
            "2023-02-04 06:10:48,184 INFO     pid:15041 util.util:236:enumerateWithEstimate E18 Training    4/23, done at 2023-02-04 06:11:45, 0:01:06\n",
            "2023-02-04 06:11:00,965 INFO     pid:15041 util.util:236:enumerateWithEstimate E18 Training    8/23, done at 2023-02-04 06:11:45, 0:01:07\n",
            "2023-02-04 06:11:26,585 INFO     pid:15041 util.util:236:enumerateWithEstimate E18 Training   16/23, done at 2023-02-04 06:11:45, 0:01:07\n",
            "2023-02-04 06:11:44,325 WARNING  pid:15041 util.util:249:enumerateWithEstimate E18 Training ----/23, done at 2023-02-04 06:11:44\n",
            "2023-02-04 06:11:44,329 INFO     pid:15041 3DUnet:004:logMetrics E18 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:11:44,332 INFO     pid:15041 3DUnet:035:logMetrics E18 trn      0.1350 loss, 0.0404 precision, 0.5077 recall, 0.0748 f1 score\n",
            "2023-02-04 06:11:44,334 INFO     pid:15041 3DUnet:045:logMetrics E18 trn_all  0.1350 loss,  50.8% tp,  49.2% fn,    1206.2% fp\n",
            "2023-02-04 06:11:44,337 INFO     pid:15041 3DUnet:002:<module> Epoch 19 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:11:44,339 WARNING  pid:15041 util.util:219:enumerateWithEstimate E19 Training ----/23, starting\n",
            "2023-02-04 06:12:01,514 INFO     pid:15041 util.util:236:enumerateWithEstimate E19 Training    4/23, done at 2023-02-04 06:12:58, 0:01:06\n",
            "2023-02-04 06:12:14,302 INFO     pid:15041 util.util:236:enumerateWithEstimate E19 Training    8/23, done at 2023-02-04 06:12:58, 0:01:06\n",
            "2023-02-04 06:12:40,018 INFO     pid:15041 util.util:236:enumerateWithEstimate E19 Training   16/23, done at 2023-02-04 06:12:59, 0:01:07\n",
            "2023-02-04 06:12:57,756 WARNING  pid:15041 util.util:249:enumerateWithEstimate E19 Training ----/23, done at 2023-02-04 06:12:57\n",
            "2023-02-04 06:12:57,758 INFO     pid:15041 3DUnet:004:logMetrics E19 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:12:57,762 INFO     pid:15041 3DUnet:035:logMetrics E19 trn      0.1134 loss, 0.0401 precision, 0.5077 recall, 0.0742 f1 score\n",
            "2023-02-04 06:12:57,763 INFO     pid:15041 3DUnet:045:logMetrics E19 trn_all  0.1134 loss,  50.8% tp,  49.2% fn,    1216.8% fp\n",
            "2023-02-04 06:12:57,769 INFO     pid:15041 3DUnet:002:<module> Epoch 20 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:12:57,771 WARNING  pid:15041 util.util:219:enumerateWithEstimate E20 Training ----/23, starting\n",
            "2023-02-04 06:13:14,909 INFO     pid:15041 util.util:236:enumerateWithEstimate E20 Training    4/23, done at 2023-02-04 06:14:12, 0:01:06\n",
            "2023-02-04 06:13:27,735 INFO     pid:15041 util.util:236:enumerateWithEstimate E20 Training    8/23, done at 2023-02-04 06:14:12, 0:01:07\n",
            "2023-02-04 06:13:53,212 INFO     pid:15041 util.util:236:enumerateWithEstimate E20 Training   16/23, done at 2023-02-04 06:14:12, 0:01:06\n",
            "2023-02-04 06:14:11,004 WARNING  pid:15041 util.util:249:enumerateWithEstimate E20 Training ----/23, done at 2023-02-04 06:14:11\n",
            "2023-02-04 06:14:11,006 INFO     pid:15041 3DUnet:004:logMetrics E20 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:14:11,012 INFO     pid:15041 3DUnet:035:logMetrics E20 trn      0.1258 loss, 0.0400 precision, 0.5064 recall, 0.0741 f1 score\n",
            "2023-02-04 06:14:11,013 INFO     pid:15041 3DUnet:045:logMetrics E20 trn_all  0.1258 loss,  50.6% tp,  49.4% fn,    1215.3% fp\n",
            "2023-02-04 06:14:11,021 WARNING  pid:15041 util.util:219:enumerateWithEstimate E20 Validation  ----/3, starting\n",
            "2023-02-04 06:14:11,447 WARNING  pid:15041 util.util:249:enumerateWithEstimate E20 Validation  ----/3, done at 2023-02-04 06:14:11\n",
            "2023-02-04 06:14:13,451 INFO     pid:15041 3DUnet:004:logMetrics E20 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:14:13,455 INFO     pid:15041 3DUnet:035:logMetrics E20 val      0.1771 loss, 0.0234 precision, 0.5007 recall, 0.0447 f1 score\n",
            "2023-02-04 06:14:13,458 INFO     pid:15041 3DUnet:045:logMetrics E20 val_all  0.1771 loss,  50.1% tp,  49.9% fn,    2088.4% fp\n",
            "2023-02-04 06:14:14,220 INFO     pid:15041 3DUnet:026:saveModel Model was saved to /gdrive/MyDrive/LiTS_sample/models/bonemeta_fn_0_3D_Unet_DropRes_lv5_All128_model_epoch20\n",
            "2023-02-04 06:14:14,774 INFO     pid:15041 3DUnet:032:saveModel SHA1: e75e470184bb6a79c56957559c241411b772bb29\n",
            "2023-02-04 06:14:14,776 INFO     pid:15041 3DUnet:002:<module> Epoch 21 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:14:14,781 WARNING  pid:15041 util.util:219:enumerateWithEstimate E21 Training ----/23, starting\n",
            "2023-02-04 06:14:32,005 INFO     pid:15041 util.util:236:enumerateWithEstimate E21 Training    4/23, done at 2023-02-04 06:15:29, 0:01:07\n",
            "2023-02-04 06:14:44,824 INFO     pid:15041 util.util:236:enumerateWithEstimate E21 Training    8/23, done at 2023-02-04 06:15:29, 0:01:07\n",
            "2023-02-04 06:15:10,438 INFO     pid:15041 util.util:236:enumerateWithEstimate E21 Training   16/23, done at 2023-02-04 06:15:29, 0:01:07\n",
            "2023-02-04 06:15:28,187 WARNING  pid:15041 util.util:249:enumerateWithEstimate E21 Training ----/23, done at 2023-02-04 06:15:28\n",
            "2023-02-04 06:15:28,190 INFO     pid:15041 3DUnet:004:logMetrics E21 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:15:28,192 INFO     pid:15041 3DUnet:035:logMetrics E21 trn      0.1139 loss, 0.0394 precision, 0.5063 recall, 0.0731 f1 score\n",
            "2023-02-04 06:15:28,193 INFO     pid:15041 3DUnet:045:logMetrics E21 trn_all  0.1139 loss,  50.6% tp,  49.4% fn,    1235.0% fp\n",
            "2023-02-04 06:15:28,200 INFO     pid:15041 3DUnet:002:<module> Epoch 22 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:15:28,202 WARNING  pid:15041 util.util:219:enumerateWithEstimate E22 Training ----/23, starting\n",
            "2023-02-04 06:15:45,466 INFO     pid:15041 util.util:236:enumerateWithEstimate E22 Training    4/23, done at 2023-02-04 06:16:43, 0:01:07\n",
            "2023-02-04 06:15:58,251 INFO     pid:15041 util.util:236:enumerateWithEstimate E22 Training    8/23, done at 2023-02-04 06:16:43, 0:01:07\n",
            "2023-02-04 06:16:23,931 INFO     pid:15041 util.util:236:enumerateWithEstimate E22 Training   16/23, done at 2023-02-04 06:16:43, 0:01:07\n",
            "2023-02-04 06:16:41,649 WARNING  pid:15041 util.util:249:enumerateWithEstimate E22 Training ----/23, done at 2023-02-04 06:16:41\n",
            "2023-02-04 06:16:41,653 INFO     pid:15041 3DUnet:004:logMetrics E22 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:16:41,656 INFO     pid:15041 3DUnet:035:logMetrics E22 trn      0.1150 loss, 0.0394 precision, 0.5061 recall, 0.0732 f1 score\n",
            "2023-02-04 06:16:41,658 INFO     pid:15041 3DUnet:045:logMetrics E22 trn_all  0.1150 loss,  50.6% tp,  49.4% fn,    1232.5% fp\n",
            "2023-02-04 06:16:41,662 INFO     pid:15041 3DUnet:002:<module> Epoch 23 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:16:41,665 WARNING  pid:15041 util.util:219:enumerateWithEstimate E23 Training ----/23, starting\n",
            "2023-02-04 06:16:58,844 INFO     pid:15041 util.util:236:enumerateWithEstimate E23 Training    4/23, done at 2023-02-04 06:17:56, 0:01:07\n",
            "2023-02-04 06:17:11,577 INFO     pid:15041 util.util:236:enumerateWithEstimate E23 Training    8/23, done at 2023-02-04 06:17:56, 0:01:06\n",
            "2023-02-04 06:17:37,125 INFO     pid:15041 util.util:236:enumerateWithEstimate E23 Training   16/23, done at 2023-02-04 06:17:56, 0:01:07\n",
            "2023-02-04 06:17:54,869 WARNING  pid:15041 util.util:249:enumerateWithEstimate E23 Training ----/23, done at 2023-02-04 06:17:54\n",
            "2023-02-04 06:17:54,874 INFO     pid:15041 3DUnet:004:logMetrics E23 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:17:54,876 INFO     pid:15041 3DUnet:035:logMetrics E23 trn      0.1122 loss, 0.0415 precision, 0.5060 recall, 0.0768 f1 score\n",
            "2023-02-04 06:17:54,879 INFO     pid:15041 3DUnet:045:logMetrics E23 trn_all  0.1122 loss,  50.6% tp,  49.4% fn,    1167.9% fp\n",
            "2023-02-04 06:17:54,883 INFO     pid:15041 3DUnet:002:<module> Epoch 24 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:17:54,886 WARNING  pid:15041 util.util:219:enumerateWithEstimate E24 Training ----/23, starting\n",
            "2023-02-04 06:18:11,939 INFO     pid:15041 util.util:236:enumerateWithEstimate E24 Training    4/23, done at 2023-02-04 06:19:09, 0:01:06\n",
            "2023-02-04 06:18:24,683 INFO     pid:15041 util.util:236:enumerateWithEstimate E24 Training    8/23, done at 2023-02-04 06:19:09, 0:01:06\n",
            "2023-02-04 06:18:50,071 INFO     pid:15041 util.util:236:enumerateWithEstimate E24 Training   16/23, done at 2023-02-04 06:19:09, 0:01:06\n",
            "2023-02-04 06:19:07,863 WARNING  pid:15041 util.util:249:enumerateWithEstimate E24 Training ----/23, done at 2023-02-04 06:19:07\n",
            "2023-02-04 06:19:07,867 INFO     pid:15041 3DUnet:004:logMetrics E24 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:19:07,871 INFO     pid:15041 3DUnet:035:logMetrics E24 trn      0.1142 loss, 0.0397 precision, 0.5055 recall, 0.0735 f1 score\n",
            "2023-02-04 06:19:07,872 INFO     pid:15041 3DUnet:045:logMetrics E24 trn_all  0.1142 loss,  50.5% tp,  49.5% fn,    1224.2% fp\n",
            "2023-02-04 06:19:07,875 INFO     pid:15041 3DUnet:002:<module> Epoch 25 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:19:07,877 WARNING  pid:15041 util.util:219:enumerateWithEstimate E25 Training ----/23, starting\n",
            "2023-02-04 06:19:25,005 INFO     pid:15041 util.util:236:enumerateWithEstimate E25 Training    4/23, done at 2023-02-04 06:20:22, 0:01:07\n",
            "2023-02-04 06:19:37,789 INFO     pid:15041 util.util:236:enumerateWithEstimate E25 Training    8/23, done at 2023-02-04 06:20:22, 0:01:07\n",
            "2023-02-04 06:20:03,350 INFO     pid:15041 util.util:236:enumerateWithEstimate E25 Training   16/23, done at 2023-02-04 06:20:22, 0:01:07\n",
            "2023-02-04 06:20:21,121 WARNING  pid:15041 util.util:249:enumerateWithEstimate E25 Training ----/23, done at 2023-02-04 06:20:21\n",
            "2023-02-04 06:20:21,125 INFO     pid:15041 3DUnet:004:logMetrics E25 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:20:21,130 INFO     pid:15041 3DUnet:035:logMetrics E25 trn      0.1115 loss, 0.0419 precision, 0.5051 recall, 0.0774 f1 score\n",
            "2023-02-04 06:20:21,131 INFO     pid:15041 3DUnet:045:logMetrics E25 trn_all  0.1115 loss,  50.5% tp,  49.5% fn,    1155.4% fp\n",
            "2023-02-04 06:20:21,134 INFO     pid:15041 3DUnet:002:<module> Epoch 26 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:20:21,136 WARNING  pid:15041 util.util:219:enumerateWithEstimate E26 Training ----/23, starting\n",
            "2023-02-04 06:20:38,352 INFO     pid:15041 util.util:236:enumerateWithEstimate E26 Training    4/23, done at 2023-02-04 06:21:35, 0:01:06\n",
            "2023-02-04 06:20:51,132 INFO     pid:15041 util.util:236:enumerateWithEstimate E26 Training    8/23, done at 2023-02-04 06:21:35, 0:01:07\n",
            "2023-02-04 06:21:16,768 INFO     pid:15041 util.util:236:enumerateWithEstimate E26 Training   16/23, done at 2023-02-04 06:21:35, 0:01:07\n",
            "2023-02-04 06:21:34,483 WARNING  pid:15041 util.util:249:enumerateWithEstimate E26 Training ----/23, done at 2023-02-04 06:21:34\n",
            "2023-02-04 06:21:34,488 INFO     pid:15041 3DUnet:004:logMetrics E26 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:21:34,491 INFO     pid:15041 3DUnet:035:logMetrics E26 trn      0.0955 loss, 0.0377 precision, 0.5055 recall, 0.0701 f1 score\n",
            "2023-02-04 06:21:34,492 INFO     pid:15041 3DUnet:045:logMetrics E26 trn_all  0.0955 loss,  50.6% tp,  49.4% fn,    1291.7% fp\n",
            "2023-02-04 06:21:34,495 INFO     pid:15041 3DUnet:002:<module> Epoch 27 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:21:34,497 WARNING  pid:15041 util.util:219:enumerateWithEstimate E27 Training ----/23, starting\n",
            "2023-02-04 06:21:51,631 INFO     pid:15041 util.util:236:enumerateWithEstimate E27 Training    4/23, done at 2023-02-04 06:22:49, 0:01:06\n",
            "2023-02-04 06:22:04,479 INFO     pid:15041 util.util:236:enumerateWithEstimate E27 Training    8/23, done at 2023-02-04 06:22:49, 0:01:07\n",
            "2023-02-04 06:22:30,084 INFO     pid:15041 util.util:236:enumerateWithEstimate E27 Training   16/23, done at 2023-02-04 06:22:49, 0:01:07\n",
            "2023-02-04 06:22:47,837 WARNING  pid:15041 util.util:249:enumerateWithEstimate E27 Training ----/23, done at 2023-02-04 06:22:47\n",
            "2023-02-04 06:22:47,841 INFO     pid:15041 3DUnet:004:logMetrics E27 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:22:47,845 INFO     pid:15041 3DUnet:035:logMetrics E27 trn      0.1062 loss, 0.0416 precision, 0.5047 recall, 0.0768 f1 score\n",
            "2023-02-04 06:22:47,846 INFO     pid:15041 3DUnet:045:logMetrics E27 trn_all  0.1062 loss,  50.5% tp,  49.5% fn,    1164.3% fp\n",
            "2023-02-04 06:22:47,853 INFO     pid:15041 3DUnet:002:<module> Epoch 28 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:22:47,855 WARNING  pid:15041 util.util:219:enumerateWithEstimate E28 Training ----/23, starting\n",
            "2023-02-04 06:23:04,806 INFO     pid:15041 util.util:236:enumerateWithEstimate E28 Training    4/23, done at 2023-02-04 06:24:01, 0:01:06\n",
            "2023-02-04 06:23:17,580 INFO     pid:15041 util.util:236:enumerateWithEstimate E28 Training    8/23, done at 2023-02-04 06:24:02, 0:01:06\n",
            "2023-02-04 06:23:43,114 INFO     pid:15041 util.util:236:enumerateWithEstimate E28 Training   16/23, done at 2023-02-04 06:24:02, 0:01:06\n",
            "2023-02-04 06:24:00,879 WARNING  pid:15041 util.util:249:enumerateWithEstimate E28 Training ----/23, done at 2023-02-04 06:24:00\n",
            "2023-02-04 06:24:00,884 INFO     pid:15041 3DUnet:004:logMetrics E28 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:24:00,886 INFO     pid:15041 3DUnet:035:logMetrics E28 trn      0.0996 loss, 0.0398 precision, 0.5047 recall, 0.0738 f1 score\n",
            "2023-02-04 06:24:00,888 INFO     pid:15041 3DUnet:045:logMetrics E28 trn_all  0.0996 loss,  50.5% tp,  49.5% fn,    1217.2% fp\n",
            "2023-02-04 06:24:00,893 INFO     pid:15041 3DUnet:002:<module> Epoch 29 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:24:00,897 WARNING  pid:15041 util.util:219:enumerateWithEstimate E29 Training ----/23, starting\n",
            "2023-02-04 06:24:18,109 INFO     pid:15041 util.util:236:enumerateWithEstimate E29 Training    4/23, done at 2023-02-04 06:25:15, 0:01:07\n",
            "2023-02-04 06:24:30,905 INFO     pid:15041 util.util:236:enumerateWithEstimate E29 Training    8/23, done at 2023-02-04 06:25:15, 0:01:07\n",
            "2023-02-04 06:24:56,343 INFO     pid:15041 util.util:236:enumerateWithEstimate E29 Training   16/23, done at 2023-02-04 06:25:15, 0:01:06\n",
            "2023-02-04 06:25:14,126 WARNING  pid:15041 util.util:249:enumerateWithEstimate E29 Training ----/23, done at 2023-02-04 06:25:14\n",
            "2023-02-04 06:25:14,128 INFO     pid:15041 3DUnet:004:logMetrics E29 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:25:14,133 INFO     pid:15041 3DUnet:035:logMetrics E29 trn      0.0909 loss, 0.0378 precision, 0.5047 recall, 0.0703 f1 score\n",
            "2023-02-04 06:25:14,139 INFO     pid:15041 3DUnet:045:logMetrics E29 trn_all  0.0909 loss,  50.5% tp,  49.5% fn,    1286.0% fp\n",
            "2023-02-04 06:25:14,143 INFO     pid:15041 3DUnet:002:<module> Epoch 30 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:25:14,145 WARNING  pid:15041 util.util:219:enumerateWithEstimate E30 Training ----/23, starting\n",
            "2023-02-04 06:25:31,234 INFO     pid:15041 util.util:236:enumerateWithEstimate E30 Training    4/23, done at 2023-02-04 06:26:28, 0:01:06\n",
            "2023-02-04 06:25:43,897 INFO     pid:15041 util.util:236:enumerateWithEstimate E30 Training    8/23, done at 2023-02-04 06:26:28, 0:01:06\n",
            "2023-02-04 06:26:09,488 INFO     pid:15041 util.util:236:enumerateWithEstimate E30 Training   16/23, done at 2023-02-04 06:26:28, 0:01:06\n",
            "2023-02-04 06:26:27,212 WARNING  pid:15041 util.util:249:enumerateWithEstimate E30 Training ----/23, done at 2023-02-04 06:26:27\n",
            "2023-02-04 06:26:27,216 INFO     pid:15041 3DUnet:004:logMetrics E30 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:26:27,219 INFO     pid:15041 3DUnet:035:logMetrics E30 trn      0.1109 loss, 0.0423 precision, 0.5042 recall, 0.0780 f1 score\n",
            "2023-02-04 06:26:27,221 INFO     pid:15041 3DUnet:045:logMetrics E30 trn_all  0.1109 loss,  50.4% tp,  49.6% fn,    1141.6% fp\n",
            "2023-02-04 06:26:27,226 WARNING  pid:15041 util.util:219:enumerateWithEstimate E30 Validation  ----/3, starting\n",
            "2023-02-04 06:26:27,667 WARNING  pid:15041 util.util:249:enumerateWithEstimate E30 Validation  ----/3, done at 2023-02-04 06:26:27\n",
            "2023-02-04 06:26:29,675 INFO     pid:15041 3DUnet:004:logMetrics E30 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:26:29,678 INFO     pid:15041 3DUnet:035:logMetrics E30 val      0.1699 loss, 0.0234 precision, 0.5013 recall, 0.0448 f1 score\n",
            "2023-02-04 06:26:29,680 INFO     pid:15041 3DUnet:045:logMetrics E30 val_all  0.1699 loss,  50.1% tp,  49.9% fn,    2088.5% fp\n",
            "2023-02-04 06:26:30,475 INFO     pid:15041 3DUnet:026:saveModel Model was saved to /gdrive/MyDrive/LiTS_sample/models/bonemeta_fn_0_3D_Unet_DropRes_lv5_All128_model_epoch30\n",
            "2023-02-04 06:26:31,002 INFO     pid:15041 3DUnet:032:saveModel SHA1: d31739dd6788a53424234cfbaa2d2a46852316b1\n",
            "2023-02-04 06:26:31,005 INFO     pid:15041 3DUnet:002:<module> Epoch 31 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:26:31,008 WARNING  pid:15041 util.util:219:enumerateWithEstimate E31 Training ----/23, starting\n",
            "2023-02-04 06:26:48,312 INFO     pid:15041 util.util:236:enumerateWithEstimate E31 Training    4/23, done at 2023-02-04 06:27:45, 0:01:06\n",
            "2023-02-04 06:27:01,162 INFO     pid:15041 util.util:236:enumerateWithEstimate E31 Training    8/23, done at 2023-02-04 06:27:45, 0:01:07\n",
            "2023-02-04 06:27:26,865 INFO     pid:15041 util.util:236:enumerateWithEstimate E31 Training   16/23, done at 2023-02-04 06:27:46, 0:01:07\n",
            "2023-02-04 06:27:44,577 WARNING  pid:15041 util.util:249:enumerateWithEstimate E31 Training ----/23, done at 2023-02-04 06:27:44\n",
            "2023-02-04 06:27:44,583 INFO     pid:15041 3DUnet:004:logMetrics E31 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:27:44,585 INFO     pid:15041 3DUnet:035:logMetrics E31 trn      0.0946 loss, 0.0393 precision, 0.5045 recall, 0.0729 f1 score\n",
            "2023-02-04 06:27:44,587 INFO     pid:15041 3DUnet:045:logMetrics E31 trn_all  0.0946 loss,  50.5% tp,  49.5% fn,    1233.7% fp\n",
            "2023-02-04 06:27:44,593 INFO     pid:15041 3DUnet:002:<module> Epoch 32 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:27:44,596 WARNING  pid:15041 util.util:219:enumerateWithEstimate E32 Training ----/23, starting\n",
            "2023-02-04 06:28:01,810 INFO     pid:15041 util.util:236:enumerateWithEstimate E32 Training    4/23, done at 2023-02-04 06:28:59, 0:01:07\n",
            "2023-02-04 06:28:14,659 INFO     pid:15041 util.util:236:enumerateWithEstimate E32 Training    8/23, done at 2023-02-04 06:28:59, 0:01:07\n",
            "2023-02-04 06:28:40,252 INFO     pid:15041 util.util:236:enumerateWithEstimate E32 Training   16/23, done at 2023-02-04 06:28:59, 0:01:07\n",
            "2023-02-04 06:28:57,950 WARNING  pid:15041 util.util:249:enumerateWithEstimate E32 Training ----/23, done at 2023-02-04 06:28:57\n",
            "2023-02-04 06:28:57,954 INFO     pid:15041 3DUnet:004:logMetrics E32 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:28:57,956 INFO     pid:15041 3DUnet:035:logMetrics E32 trn      0.1058 loss, 0.0402 precision, 0.5043 recall, 0.0744 f1 score\n",
            "2023-02-04 06:28:57,958 INFO     pid:15041 3DUnet:045:logMetrics E32 trn_all  0.1058 loss,  50.4% tp,  49.6% fn,    1204.5% fp\n",
            "2023-02-04 06:28:57,962 INFO     pid:15041 3DUnet:002:<module> Epoch 33 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:28:57,966 WARNING  pid:15041 util.util:219:enumerateWithEstimate E33 Training ----/23, starting\n",
            "2023-02-04 06:29:15,101 INFO     pid:15041 util.util:236:enumerateWithEstimate E33 Training    4/23, done at 2023-02-04 06:30:12, 0:01:06\n",
            "2023-02-04 06:29:27,940 INFO     pid:15041 util.util:236:enumerateWithEstimate E33 Training    8/23, done at 2023-02-04 06:30:12, 0:01:07\n",
            "2023-02-04 06:29:53,579 INFO     pid:15041 util.util:236:enumerateWithEstimate E33 Training   16/23, done at 2023-02-04 06:30:12, 0:01:07\n",
            "2023-02-04 06:30:11,388 WARNING  pid:15041 util.util:249:enumerateWithEstimate E33 Training ----/23, done at 2023-02-04 06:30:11\n",
            "2023-02-04 06:30:11,391 INFO     pid:15041 3DUnet:004:logMetrics E33 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:30:11,395 INFO     pid:15041 3DUnet:035:logMetrics E33 trn      0.1029 loss, 0.0418 precision, 0.5042 recall, 0.0772 f1 score\n",
            "2023-02-04 06:30:11,397 INFO     pid:15041 3DUnet:045:logMetrics E33 trn_all  0.1029 loss,  50.4% tp,  49.6% fn,    1155.9% fp\n",
            "2023-02-04 06:30:11,404 INFO     pid:15041 3DUnet:002:<module> Epoch 34 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:30:11,407 WARNING  pid:15041 util.util:219:enumerateWithEstimate E34 Training ----/23, starting\n",
            "2023-02-04 06:30:28,448 INFO     pid:15041 util.util:236:enumerateWithEstimate E34 Training    4/23, done at 2023-02-04 06:31:25, 0:01:06\n",
            "2023-02-04 06:30:41,174 INFO     pid:15041 util.util:236:enumerateWithEstimate E34 Training    8/23, done at 2023-02-04 06:31:25, 0:01:06\n",
            "2023-02-04 06:31:06,688 INFO     pid:15041 util.util:236:enumerateWithEstimate E34 Training   16/23, done at 2023-02-04 06:31:25, 0:01:06\n",
            "2023-02-04 06:31:24,500 WARNING  pid:15041 util.util:249:enumerateWithEstimate E34 Training ----/23, done at 2023-02-04 06:31:24\n",
            "2023-02-04 06:31:24,505 INFO     pid:15041 3DUnet:004:logMetrics E34 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:31:24,508 INFO     pid:15041 3DUnet:035:logMetrics E34 trn      0.0991 loss, 0.0385 precision, 0.5036 recall, 0.0716 f1 score\n",
            "2023-02-04 06:31:24,511 INFO     pid:15041 3DUnet:045:logMetrics E34 trn_all  0.0991 loss,  50.4% tp,  49.6% fn,    1256.4% fp\n",
            "2023-02-04 06:31:24,518 INFO     pid:15041 3DUnet:002:<module> Epoch 35 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:31:24,521 WARNING  pid:15041 util.util:219:enumerateWithEstimate E35 Training ----/23, starting\n",
            "2023-02-04 06:31:41,730 INFO     pid:15041 util.util:236:enumerateWithEstimate E35 Training    4/23, done at 2023-02-04 06:32:39, 0:01:07\n",
            "2023-02-04 06:31:54,506 INFO     pid:15041 util.util:236:enumerateWithEstimate E35 Training    8/23, done at 2023-02-04 06:32:39, 0:01:07\n",
            "2023-02-04 06:32:19,941 INFO     pid:15041 util.util:236:enumerateWithEstimate E35 Training   16/23, done at 2023-02-04 06:32:39, 0:01:06\n",
            "2023-02-04 06:32:37,714 WARNING  pid:15041 util.util:249:enumerateWithEstimate E35 Training ----/23, done at 2023-02-04 06:32:37\n",
            "2023-02-04 06:32:37,716 INFO     pid:15041 3DUnet:004:logMetrics E35 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:32:37,723 INFO     pid:15041 3DUnet:035:logMetrics E35 trn      0.0864 loss, 0.0393 precision, 0.5035 recall, 0.0730 f1 score\n",
            "2023-02-04 06:32:37,727 INFO     pid:15041 3DUnet:045:logMetrics E35 trn_all  0.0864 loss,  50.3% tp,  49.7% fn,    1229.4% fp\n",
            "2023-02-04 06:32:37,730 INFO     pid:15041 3DUnet:002:<module> Epoch 36 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:32:37,733 WARNING  pid:15041 util.util:219:enumerateWithEstimate E36 Training ----/23, starting\n",
            "2023-02-04 06:32:55,361 INFO     pid:15041 util.util:236:enumerateWithEstimate E36 Training    4/23, done at 2023-02-04 06:33:52, 0:01:07\n",
            "2023-02-04 06:33:08,190 INFO     pid:15041 util.util:236:enumerateWithEstimate E36 Training    8/23, done at 2023-02-04 06:33:53, 0:01:07\n",
            "2023-02-04 06:33:33,676 INFO     pid:15041 util.util:236:enumerateWithEstimate E36 Training   16/23, done at 2023-02-04 06:33:52, 0:01:07\n",
            "2023-02-04 06:33:51,552 WARNING  pid:15041 util.util:249:enumerateWithEstimate E36 Training ----/23, done at 2023-02-04 06:33:51\n",
            "2023-02-04 06:33:51,556 INFO     pid:15041 3DUnet:004:logMetrics E36 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:33:51,559 INFO     pid:15041 3DUnet:035:logMetrics E36 trn      0.0836 loss, 0.0391 precision, 0.5036 recall, 0.0726 f1 score\n",
            "2023-02-04 06:33:51,560 INFO     pid:15041 3DUnet:045:logMetrics E36 trn_all  0.0836 loss,  50.4% tp,  49.6% fn,    1237.7% fp\n",
            "2023-02-04 06:33:51,562 INFO     pid:15041 3DUnet:002:<module> Epoch 37 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:33:51,565 WARNING  pid:15041 util.util:219:enumerateWithEstimate E37 Training ----/23, starting\n",
            "2023-02-04 06:34:08,729 INFO     pid:15041 util.util:236:enumerateWithEstimate E37 Training    4/23, done at 2023-02-04 06:35:06, 0:01:06\n",
            "2023-02-04 06:34:21,488 INFO     pid:15041 util.util:236:enumerateWithEstimate E37 Training    8/23, done at 2023-02-04 06:35:06, 0:01:06\n",
            "2023-02-04 06:34:47,104 INFO     pid:15041 util.util:236:enumerateWithEstimate E37 Training   16/23, done at 2023-02-04 06:35:06, 0:01:07\n",
            "2023-02-04 06:35:04,968 WARNING  pid:15041 util.util:249:enumerateWithEstimate E37 Training ----/23, done at 2023-02-04 06:35:04\n",
            "2023-02-04 06:35:04,970 INFO     pid:15041 3DUnet:004:logMetrics E37 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:35:04,974 INFO     pid:15041 3DUnet:035:logMetrics E37 trn      0.0975 loss, 0.0387 precision, 0.5043 recall, 0.0718 f1 score\n",
            "2023-02-04 06:35:04,976 INFO     pid:15041 3DUnet:045:logMetrics E37 trn_all  0.0975 loss,  50.4% tp,  49.6% fn,    1254.2% fp\n",
            "2023-02-04 06:35:04,981 INFO     pid:15041 3DUnet:002:<module> Epoch 38 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:35:04,983 WARNING  pid:15041 util.util:219:enumerateWithEstimate E38 Training ----/23, starting\n",
            "2023-02-04 06:35:22,588 INFO     pid:15041 util.util:236:enumerateWithEstimate E38 Training    4/23, done at 2023-02-04 06:36:19, 0:01:06\n",
            "2023-02-04 06:35:35,482 INFO     pid:15041 util.util:236:enumerateWithEstimate E38 Training    8/23, done at 2023-02-04 06:36:20, 0:01:07\n",
            "2023-02-04 06:36:01,064 INFO     pid:15041 util.util:236:enumerateWithEstimate E38 Training   16/23, done at 2023-02-04 06:36:20, 0:01:07\n",
            "2023-02-04 06:36:18,894 WARNING  pid:15041 util.util:249:enumerateWithEstimate E38 Training ----/23, done at 2023-02-04 06:36:18\n",
            "2023-02-04 06:36:18,896 INFO     pid:15041 3DUnet:004:logMetrics E38 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:36:18,902 INFO     pid:15041 3DUnet:035:logMetrics E38 trn      0.1015 loss, 0.0398 precision, 0.5033 recall, 0.0738 f1 score\n",
            "2023-02-04 06:36:18,905 INFO     pid:15041 3DUnet:045:logMetrics E38 trn_all  0.1015 loss,  50.3% tp,  49.7% fn,    1213.1% fp\n",
            "2023-02-04 06:36:18,913 INFO     pid:15041 3DUnet:002:<module> Epoch 39 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:36:18,916 WARNING  pid:15041 util.util:219:enumerateWithEstimate E39 Training ----/23, starting\n",
            "2023-02-04 06:36:36,130 INFO     pid:15041 util.util:236:enumerateWithEstimate E39 Training    4/23, done at 2023-02-04 06:37:33, 0:01:06\n",
            "2023-02-04 06:36:48,869 INFO     pid:15041 util.util:236:enumerateWithEstimate E39 Training    8/23, done at 2023-02-04 06:37:33, 0:01:06\n",
            "2023-02-04 06:37:14,454 INFO     pid:15041 util.util:236:enumerateWithEstimate E39 Training   16/23, done at 2023-02-04 06:37:33, 0:01:07\n",
            "2023-02-04 06:37:32,284 WARNING  pid:15041 util.util:249:enumerateWithEstimate E39 Training ----/23, done at 2023-02-04 06:37:32\n",
            "2023-02-04 06:37:32,287 INFO     pid:15041 3DUnet:004:logMetrics E39 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:37:32,289 INFO     pid:15041 3DUnet:035:logMetrics E39 trn      0.0807 loss, 0.0399 precision, 0.5039 recall, 0.0739 f1 score\n",
            "2023-02-04 06:37:32,291 INFO     pid:15041 3DUnet:045:logMetrics E39 trn_all  0.0807 loss,  50.4% tp,  49.6% fn,    1213.2% fp\n",
            "2023-02-04 06:37:32,298 INFO     pid:15041 3DUnet:002:<module> Epoch 40 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:37:32,300 WARNING  pid:15041 util.util:219:enumerateWithEstimate E40 Training ----/23, starting\n",
            "2023-02-04 06:37:49,530 INFO     pid:15041 util.util:236:enumerateWithEstimate E40 Training    4/23, done at 2023-02-04 06:38:46, 0:01:06\n",
            "2023-02-04 06:38:02,315 INFO     pid:15041 util.util:236:enumerateWithEstimate E40 Training    8/23, done at 2023-02-04 06:38:47, 0:01:07\n",
            "2023-02-04 06:38:27,848 INFO     pid:15041 util.util:236:enumerateWithEstimate E40 Training   16/23, done at 2023-02-04 06:38:47, 0:01:07\n",
            "2023-02-04 06:38:45,645 WARNING  pid:15041 util.util:249:enumerateWithEstimate E40 Training ----/23, done at 2023-02-04 06:38:45\n",
            "2023-02-04 06:38:45,649 INFO     pid:15041 3DUnet:004:logMetrics E40 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:38:45,652 INFO     pid:15041 3DUnet:035:logMetrics E40 trn      0.0785 loss, 0.0395 precision, 0.5035 recall, 0.0732 f1 score\n",
            "2023-02-04 06:38:45,655 INFO     pid:15041 3DUnet:045:logMetrics E40 trn_all  0.0785 loss,  50.4% tp,  49.6% fn,    1225.4% fp\n",
            "2023-02-04 06:38:45,662 WARNING  pid:15041 util.util:219:enumerateWithEstimate E40 Validation  ----/3, starting\n",
            "2023-02-04 06:38:46,102 WARNING  pid:15041 util.util:249:enumerateWithEstimate E40 Validation  ----/3, done at 2023-02-04 06:38:46\n",
            "2023-02-04 06:38:48,108 INFO     pid:15041 3DUnet:004:logMetrics E40 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:38:48,111 INFO     pid:15041 3DUnet:035:logMetrics E40 val      0.1475 loss, 0.0235 precision, 0.5030 recall, 0.0449 f1 score\n",
            "2023-02-04 06:38:48,112 INFO     pid:15041 3DUnet:045:logMetrics E40 val_all  0.1475 loss,  50.3% tp,  49.7% fn,    2088.3% fp\n",
            "2023-02-04 06:38:49,183 INFO     pid:15041 3DUnet:026:saveModel Model was saved to /gdrive/MyDrive/LiTS_sample/models/bonemeta_fn_0_3D_Unet_DropRes_lv5_All128_model_epoch40\n",
            "2023-02-04 06:38:49,688 INFO     pid:15041 3DUnet:032:saveModel SHA1: b5ab177688337eced17ef64dcd115d485bece251\n",
            "2023-02-04 06:38:49,691 INFO     pid:15041 3DUnet:002:<module> Epoch 41 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:38:49,695 WARNING  pid:15041 util.util:219:enumerateWithEstimate E41 Training ----/23, starting\n",
            "2023-02-04 06:39:06,865 INFO     pid:15041 util.util:236:enumerateWithEstimate E41 Training    4/23, done at 2023-02-04 06:40:03, 0:01:06\n",
            "2023-02-04 06:39:19,710 INFO     pid:15041 util.util:236:enumerateWithEstimate E41 Training    8/23, done at 2023-02-04 06:40:04, 0:01:07\n",
            "2023-02-04 06:39:45,304 INFO     pid:15041 util.util:236:enumerateWithEstimate E41 Training   16/23, done at 2023-02-04 06:40:04, 0:01:07\n",
            "2023-02-04 06:40:03,017 WARNING  pid:15041 util.util:249:enumerateWithEstimate E41 Training ----/23, done at 2023-02-04 06:40:03\n",
            "2023-02-04 06:40:03,022 INFO     pid:15041 3DUnet:004:logMetrics E41 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:40:03,024 INFO     pid:15041 3DUnet:035:logMetrics E41 trn      0.0797 loss, 0.0418 precision, 0.5035 recall, 0.0773 f1 score\n",
            "2023-02-04 06:40:03,027 INFO     pid:15041 3DUnet:045:logMetrics E41 trn_all  0.0797 loss,  50.3% tp,  49.7% fn,    1153.0% fp\n",
            "2023-02-04 06:40:03,030 INFO     pid:15041 3DUnet:002:<module> Epoch 42 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:40:03,034 WARNING  pid:15041 util.util:219:enumerateWithEstimate E42 Training ----/23, starting\n",
            "2023-02-04 06:40:20,251 INFO     pid:15041 util.util:236:enumerateWithEstimate E42 Training    4/23, done at 2023-02-04 06:41:17, 0:01:07\n",
            "2023-02-04 06:40:33,053 INFO     pid:15041 util.util:236:enumerateWithEstimate E42 Training    8/23, done at 2023-02-04 06:41:17, 0:01:07\n",
            "2023-02-04 06:40:58,697 INFO     pid:15041 util.util:236:enumerateWithEstimate E42 Training   16/23, done at 2023-02-04 06:41:17, 0:01:07\n",
            "2023-02-04 06:41:16,393 WARNING  pid:15041 util.util:249:enumerateWithEstimate E42 Training ----/23, done at 2023-02-04 06:41:16\n",
            "2023-02-04 06:41:16,397 INFO     pid:15041 3DUnet:004:logMetrics E42 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:41:16,399 INFO     pid:15041 3DUnet:035:logMetrics E42 trn      0.0777 loss, 0.0390 precision, 0.5035 recall, 0.0723 f1 score\n",
            "2023-02-04 06:41:16,404 INFO     pid:15041 3DUnet:045:logMetrics E42 trn_all  0.0777 loss,  50.4% tp,  49.6% fn,    1242.1% fp\n",
            "2023-02-04 06:41:16,407 INFO     pid:15041 3DUnet:002:<module> Epoch 43 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:41:16,409 WARNING  pid:15041 util.util:219:enumerateWithEstimate E43 Training ----/23, starting\n",
            "2023-02-04 06:41:33,612 INFO     pid:15041 util.util:236:enumerateWithEstimate E43 Training    4/23, done at 2023-02-04 06:42:30, 0:01:06\n",
            "2023-02-04 06:41:46,416 INFO     pid:15041 util.util:236:enumerateWithEstimate E43 Training    8/23, done at 2023-02-04 06:42:31, 0:01:07\n",
            "2023-02-04 06:42:12,077 INFO     pid:15041 util.util:236:enumerateWithEstimate E43 Training   16/23, done at 2023-02-04 06:42:31, 0:01:07\n",
            "2023-02-04 06:42:29,861 WARNING  pid:15041 util.util:249:enumerateWithEstimate E43 Training ----/23, done at 2023-02-04 06:42:29\n",
            "2023-02-04 06:42:29,866 INFO     pid:15041 3DUnet:004:logMetrics E43 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:42:29,868 INFO     pid:15041 3DUnet:035:logMetrics E43 trn      0.0842 loss, 0.0412 precision, 0.5037 recall, 0.0761 f1 score\n",
            "2023-02-04 06:42:29,870 INFO     pid:15041 3DUnet:045:logMetrics E43 trn_all  0.0842 loss,  50.4% tp,  49.6% fn,    1173.2% fp\n",
            "2023-02-04 06:42:29,876 INFO     pid:15041 3DUnet:002:<module> Epoch 44 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:42:29,878 WARNING  pid:15041 util.util:219:enumerateWithEstimate E44 Training ----/23, starting\n",
            "2023-02-04 06:42:47,155 INFO     pid:15041 util.util:236:enumerateWithEstimate E44 Training    4/23, done at 2023-02-04 06:43:44, 0:01:07\n",
            "2023-02-04 06:42:59,936 INFO     pid:15041 util.util:236:enumerateWithEstimate E44 Training    8/23, done at 2023-02-04 06:43:44, 0:01:07\n",
            "2023-02-04 06:43:25,446 INFO     pid:15041 util.util:236:enumerateWithEstimate E44 Training   16/23, done at 2023-02-04 06:43:44, 0:01:07\n",
            "2023-02-04 06:43:43,201 WARNING  pid:15041 util.util:249:enumerateWithEstimate E44 Training ----/23, done at 2023-02-04 06:43:43\n",
            "2023-02-04 06:43:43,205 INFO     pid:15041 3DUnet:004:logMetrics E44 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:43:43,211 INFO     pid:15041 3DUnet:035:logMetrics E44 trn      0.0897 loss, 0.0421 precision, 0.5036 recall, 0.0777 f1 score\n",
            "2023-02-04 06:43:43,212 INFO     pid:15041 3DUnet:045:logMetrics E44 trn_all  0.0897 loss,  50.4% tp,  49.6% fn,    1146.5% fp\n",
            "2023-02-04 06:43:43,214 INFO     pid:15041 3DUnet:002:<module> Epoch 45 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:43:43,218 WARNING  pid:15041 util.util:219:enumerateWithEstimate E45 Training ----/23, starting\n",
            "2023-02-04 06:44:00,391 INFO     pid:15041 util.util:236:enumerateWithEstimate E45 Training    4/23, done at 2023-02-04 06:44:57, 0:01:07\n",
            "2023-02-04 06:44:13,112 INFO     pid:15041 util.util:236:enumerateWithEstimate E45 Training    8/23, done at 2023-02-04 06:44:57, 0:01:06\n",
            "2023-02-04 06:44:38,742 INFO     pid:15041 util.util:236:enumerateWithEstimate E45 Training   16/23, done at 2023-02-04 06:44:57, 0:01:07\n",
            "2023-02-04 06:44:56,470 WARNING  pid:15041 util.util:249:enumerateWithEstimate E45 Training ----/23, done at 2023-02-04 06:44:56\n",
            "2023-02-04 06:44:56,471 INFO     pid:15041 3DUnet:004:logMetrics E45 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:44:56,477 INFO     pid:15041 3DUnet:035:logMetrics E45 trn      0.0922 loss, 0.0429 precision, 0.5032 recall, 0.0791 f1 score\n",
            "2023-02-04 06:44:56,479 INFO     pid:15041 3DUnet:045:logMetrics E45 trn_all  0.0922 loss,  50.3% tp,  49.7% fn,    1121.4% fp\n",
            "2023-02-04 06:44:56,483 INFO     pid:15041 3DUnet:002:<module> Epoch 46 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:44:56,485 WARNING  pid:15041 util.util:219:enumerateWithEstimate E46 Training ----/23, starting\n",
            "2023-02-04 06:45:13,600 INFO     pid:15041 util.util:236:enumerateWithEstimate E46 Training    4/23, done at 2023-02-04 06:46:11, 0:01:07\n",
            "2023-02-04 06:45:26,391 INFO     pid:15041 util.util:236:enumerateWithEstimate E46 Training    8/23, done at 2023-02-04 06:46:11, 0:01:07\n",
            "2023-02-04 06:45:51,937 INFO     pid:15041 util.util:236:enumerateWithEstimate E46 Training   16/23, done at 2023-02-04 06:46:11, 0:01:07\n",
            "2023-02-04 06:46:09,706 WARNING  pid:15041 util.util:249:enumerateWithEstimate E46 Training ----/23, done at 2023-02-04 06:46:09\n",
            "2023-02-04 06:46:09,708 INFO     pid:15041 3DUnet:004:logMetrics E46 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:46:09,715 INFO     pid:15041 3DUnet:035:logMetrics E46 trn      0.1095 loss, 0.0394 precision, 0.5034 recall, 0.0731 f1 score\n",
            "2023-02-04 06:46:09,716 INFO     pid:15041 3DUnet:045:logMetrics E46 trn_all  0.1095 loss,  50.3% tp,  49.7% fn,    1226.5% fp\n",
            "2023-02-04 06:46:09,721 INFO     pid:15041 3DUnet:002:<module> Epoch 47 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:46:09,724 WARNING  pid:15041 util.util:219:enumerateWithEstimate E47 Training ----/23, starting\n",
            "2023-02-04 06:46:26,784 INFO     pid:15041 util.util:236:enumerateWithEstimate E47 Training    4/23, done at 2023-02-04 06:47:23, 0:01:05\n",
            "2023-02-04 06:46:39,625 INFO     pid:15041 util.util:236:enumerateWithEstimate E47 Training    8/23, done at 2023-02-04 06:47:24, 0:01:06\n",
            "2023-02-04 06:47:05,194 INFO     pid:15041 util.util:236:enumerateWithEstimate E47 Training   16/23, done at 2023-02-04 06:47:24, 0:01:06\n",
            "2023-02-04 06:47:22,961 WARNING  pid:15041 util.util:249:enumerateWithEstimate E47 Training ----/23, done at 2023-02-04 06:47:22\n",
            "2023-02-04 06:47:22,965 INFO     pid:15041 3DUnet:004:logMetrics E47 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:47:22,971 INFO     pid:15041 3DUnet:035:logMetrics E47 trn      0.1111 loss, 0.0408 precision, 0.5031 recall, 0.0755 f1 score\n",
            "2023-02-04 06:47:22,974 INFO     pid:15041 3DUnet:045:logMetrics E47 trn_all  0.1111 loss,  50.3% tp,  49.7% fn,    1182.7% fp\n",
            "2023-02-04 06:47:22,978 INFO     pid:15041 3DUnet:002:<module> Epoch 48 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:47:22,981 WARNING  pid:15041 util.util:219:enumerateWithEstimate E48 Training ----/23, starting\n",
            "2023-02-04 06:47:40,114 INFO     pid:15041 util.util:236:enumerateWithEstimate E48 Training    4/23, done at 2023-02-04 06:48:37, 0:01:06\n",
            "2023-02-04 06:47:52,865 INFO     pid:15041 util.util:236:enumerateWithEstimate E48 Training    8/23, done at 2023-02-04 06:48:37, 0:01:06\n",
            "2023-02-04 06:48:18,377 INFO     pid:15041 util.util:236:enumerateWithEstimate E48 Training   16/23, done at 2023-02-04 06:48:37, 0:01:06\n",
            "2023-02-04 06:48:36,200 WARNING  pid:15041 util.util:249:enumerateWithEstimate E48 Training ----/23, done at 2023-02-04 06:48:36\n",
            "2023-02-04 06:48:36,202 INFO     pid:15041 3DUnet:004:logMetrics E48 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:48:36,205 INFO     pid:15041 3DUnet:035:logMetrics E48 trn      0.0904 loss, 0.0401 precision, 0.5031 recall, 0.0743 f1 score\n",
            "2023-02-04 06:48:36,206 INFO     pid:15041 3DUnet:045:logMetrics E48 trn_all  0.0904 loss,  50.3% tp,  49.7% fn,    1204.8% fp\n",
            "2023-02-04 06:48:36,212 INFO     pid:15041 3DUnet:002:<module> Epoch 49 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:48:36,214 WARNING  pid:15041 util.util:219:enumerateWithEstimate E49 Training ----/23, starting\n",
            "2023-02-04 06:48:53,417 INFO     pid:15041 util.util:236:enumerateWithEstimate E49 Training    4/23, done at 2023-02-04 06:49:50, 0:01:06\n",
            "2023-02-04 06:49:06,127 INFO     pid:15041 util.util:236:enumerateWithEstimate E49 Training    8/23, done at 2023-02-04 06:49:50, 0:01:06\n",
            "2023-02-04 06:49:31,558 INFO     pid:15041 util.util:236:enumerateWithEstimate E49 Training   16/23, done at 2023-02-04 06:49:50, 0:01:06\n",
            "2023-02-04 06:49:49,320 WARNING  pid:15041 util.util:249:enumerateWithEstimate E49 Training ----/23, done at 2023-02-04 06:49:49\n",
            "2023-02-04 06:49:49,322 INFO     pid:15041 3DUnet:004:logMetrics E49 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:49:49,326 INFO     pid:15041 3DUnet:035:logMetrics E49 trn      0.0907 loss, 0.0388 precision, 0.5029 recall, 0.0721 f1 score\n",
            "2023-02-04 06:49:49,328 INFO     pid:15041 3DUnet:045:logMetrics E49 trn_all  0.0907 loss,  50.3% tp,  49.7% fn,    1245.2% fp\n",
            "2023-02-04 06:49:49,335 INFO     pid:15041 3DUnet:002:<module> Epoch 50 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:49:49,338 WARNING  pid:15041 util.util:219:enumerateWithEstimate E50 Training ----/23, starting\n",
            "2023-02-04 06:50:06,488 INFO     pid:15041 util.util:236:enumerateWithEstimate E50 Training    4/23, done at 2023-02-04 06:51:03, 0:01:06\n",
            "2023-02-04 06:50:19,367 INFO     pid:15041 util.util:236:enumerateWithEstimate E50 Training    8/23, done at 2023-02-04 06:51:04, 0:01:07\n",
            "2023-02-04 06:50:44,950 INFO     pid:15041 util.util:236:enumerateWithEstimate E50 Training   16/23, done at 2023-02-04 06:51:04, 0:01:07\n",
            "2023-02-04 06:51:02,716 WARNING  pid:15041 util.util:249:enumerateWithEstimate E50 Training ----/23, done at 2023-02-04 06:51:02\n",
            "2023-02-04 06:51:02,720 INFO     pid:15041 3DUnet:004:logMetrics E50 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:51:02,722 INFO     pid:15041 3DUnet:035:logMetrics E50 trn      0.1000 loss, 0.0405 precision, 0.5029 recall, 0.0750 f1 score\n",
            "2023-02-04 06:51:02,724 INFO     pid:15041 3DUnet:045:logMetrics E50 trn_all  0.1000 loss,  50.3% tp,  49.7% fn,    1191.5% fp\n",
            "2023-02-04 06:51:02,729 WARNING  pid:15041 util.util:219:enumerateWithEstimate E50 Validation  ----/3, starting\n",
            "2023-02-04 06:51:03,165 WARNING  pid:15041 util.util:249:enumerateWithEstimate E50 Validation  ----/3, done at 2023-02-04 06:51:03\n",
            "2023-02-04 06:51:05,159 INFO     pid:15041 3DUnet:004:logMetrics E50 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:51:05,161 INFO     pid:15041 3DUnet:035:logMetrics E50 val      0.1607 loss, 0.0234 precision, 0.5010 recall, 0.0448 f1 score\n",
            "2023-02-04 06:51:05,164 INFO     pid:15041 3DUnet:045:logMetrics E50 val_all  0.1607 loss,  50.1% tp,  49.9% fn,    2088.3% fp\n",
            "2023-02-04 06:51:05,852 INFO     pid:15041 3DUnet:026:saveModel Model was saved to /gdrive/MyDrive/LiTS_sample/models/bonemeta_fn_0_3D_Unet_DropRes_lv5_All128_model_epoch50\n",
            "2023-02-04 06:51:06,383 INFO     pid:15041 3DUnet:032:saveModel SHA1: 55b6b60ba2f3472a7fc9bf4e5214a009fdcb639a\n",
            "2023-02-04 06:51:06,384 INFO     pid:15041 3DUnet:002:<module> Epoch 51 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:51:06,390 WARNING  pid:15041 util.util:219:enumerateWithEstimate E51 Training ----/23, starting\n",
            "2023-02-04 06:51:23,525 INFO     pid:15041 util.util:236:enumerateWithEstimate E51 Training    4/23, done at 2023-02-04 06:52:21, 0:01:07\n",
            "2023-02-04 06:51:36,370 INFO     pid:15041 util.util:236:enumerateWithEstimate E51 Training    8/23, done at 2023-02-04 06:52:21, 0:01:07\n",
            "2023-02-04 06:52:01,987 INFO     pid:15041 util.util:236:enumerateWithEstimate E51 Training   16/23, done at 2023-02-04 06:52:21, 0:01:07\n",
            "2023-02-04 06:52:19,675 WARNING  pid:15041 util.util:249:enumerateWithEstimate E51 Training ----/23, done at 2023-02-04 06:52:19\n",
            "2023-02-04 06:52:19,679 INFO     pid:15041 3DUnet:004:logMetrics E51 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:52:19,684 INFO     pid:15041 3DUnet:035:logMetrics E51 trn      0.0820 loss, 0.0383 precision, 0.5030 recall, 0.0711 f1 score\n",
            "2023-02-04 06:52:19,686 INFO     pid:15041 3DUnet:045:logMetrics E51 trn_all  0.0820 loss,  50.3% tp,  49.7% fn,    1264.3% fp\n",
            "2023-02-04 06:52:19,695 INFO     pid:15041 3DUnet:002:<module> Epoch 52 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:52:19,698 WARNING  pid:15041 util.util:219:enumerateWithEstimate E52 Training ----/23, starting\n",
            "2023-02-04 06:52:36,721 INFO     pid:15041 util.util:236:enumerateWithEstimate E52 Training    4/23, done at 2023-02-04 06:53:33, 0:01:06\n",
            "2023-02-04 06:52:49,515 INFO     pid:15041 util.util:236:enumerateWithEstimate E52 Training    8/23, done at 2023-02-04 06:53:34, 0:01:06\n",
            "2023-02-04 06:53:15,104 INFO     pid:15041 util.util:236:enumerateWithEstimate E52 Training   16/23, done at 2023-02-04 06:53:34, 0:01:06\n",
            "2023-02-04 06:53:32,797 WARNING  pid:15041 util.util:249:enumerateWithEstimate E52 Training ----/23, done at 2023-02-04 06:53:32\n",
            "2023-02-04 06:53:32,803 INFO     pid:15041 3DUnet:004:logMetrics E52 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:53:32,806 INFO     pid:15041 3DUnet:035:logMetrics E52 trn      0.0803 loss, 0.0395 precision, 0.5028 recall, 0.0733 f1 score\n",
            "2023-02-04 06:53:32,807 INFO     pid:15041 3DUnet:045:logMetrics E52 trn_all  0.0803 loss,  50.3% tp,  49.7% fn,    1222.4% fp\n",
            "2023-02-04 06:53:32,811 INFO     pid:15041 3DUnet:002:<module> Epoch 53 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:53:32,813 WARNING  pid:15041 util.util:219:enumerateWithEstimate E53 Training ----/23, starting\n",
            "2023-02-04 06:53:50,021 INFO     pid:15041 util.util:236:enumerateWithEstimate E53 Training    4/23, done at 2023-02-04 06:54:47, 0:01:07\n",
            "2023-02-04 06:54:02,765 INFO     pid:15041 util.util:236:enumerateWithEstimate E53 Training    8/23, done at 2023-02-04 06:54:47, 0:01:07\n",
            "2023-02-04 06:54:28,241 INFO     pid:15041 util.util:236:enumerateWithEstimate E53 Training   16/23, done at 2023-02-04 06:54:47, 0:01:06\n",
            "2023-02-04 06:54:45,975 WARNING  pid:15041 util.util:249:enumerateWithEstimate E53 Training ----/23, done at 2023-02-04 06:54:45\n",
            "2023-02-04 06:54:45,977 INFO     pid:15041 3DUnet:004:logMetrics E53 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:54:45,983 INFO     pid:15041 3DUnet:035:logMetrics E53 trn      0.0890 loss, 0.0392 precision, 0.5030 recall, 0.0728 f1 score\n",
            "2023-02-04 06:54:45,984 INFO     pid:15041 3DUnet:045:logMetrics E53 trn_all  0.0890 loss,  50.3% tp,  49.7% fn,    1231.7% fp\n",
            "2023-02-04 06:54:45,990 INFO     pid:15041 3DUnet:002:<module> Epoch 54 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:54:45,993 WARNING  pid:15041 util.util:219:enumerateWithEstimate E54 Training ----/23, starting\n",
            "2023-02-04 06:55:03,211 INFO     pid:15041 util.util:236:enumerateWithEstimate E54 Training    4/23, done at 2023-02-04 06:56:00, 0:01:06\n",
            "2023-02-04 06:55:15,999 INFO     pid:15041 util.util:236:enumerateWithEstimate E54 Training    8/23, done at 2023-02-04 06:56:00, 0:01:07\n",
            "2023-02-04 06:55:41,533 INFO     pid:15041 util.util:236:enumerateWithEstimate E54 Training   16/23, done at 2023-02-04 06:56:00, 0:01:07\n",
            "2023-02-04 06:55:59,289 WARNING  pid:15041 util.util:249:enumerateWithEstimate E54 Training ----/23, done at 2023-02-04 06:55:59\n",
            "2023-02-04 06:55:59,296 INFO     pid:15041 3DUnet:004:logMetrics E54 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:55:59,297 INFO     pid:15041 3DUnet:035:logMetrics E54 trn      0.0878 loss, 0.0393 precision, 0.5028 recall, 0.0728 f1 score\n",
            "2023-02-04 06:55:59,299 INFO     pid:15041 3DUnet:045:logMetrics E54 trn_all  0.0878 loss,  50.3% tp,  49.7% fn,    1230.4% fp\n",
            "2023-02-04 06:55:59,307 INFO     pid:15041 3DUnet:002:<module> Epoch 55 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:55:59,311 WARNING  pid:15041 util.util:219:enumerateWithEstimate E55 Training ----/23, starting\n",
            "2023-02-04 06:56:16,509 INFO     pid:15041 util.util:236:enumerateWithEstimate E55 Training    4/23, done at 2023-02-04 06:57:13, 0:01:06\n",
            "2023-02-04 06:56:29,273 INFO     pid:15041 util.util:236:enumerateWithEstimate E55 Training    8/23, done at 2023-02-04 06:57:13, 0:01:06\n",
            "2023-02-04 06:56:54,896 INFO     pid:15041 util.util:236:enumerateWithEstimate E55 Training   16/23, done at 2023-02-04 06:57:14, 0:01:07\n",
            "2023-02-04 06:57:12,645 WARNING  pid:15041 util.util:249:enumerateWithEstimate E55 Training ----/23, done at 2023-02-04 06:57:12\n",
            "2023-02-04 06:57:12,649 INFO     pid:15041 3DUnet:004:logMetrics E55 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:57:12,651 INFO     pid:15041 3DUnet:035:logMetrics E55 trn      0.0808 loss, 0.0408 precision, 0.5028 recall, 0.0755 f1 score\n",
            "2023-02-04 06:57:12,654 INFO     pid:15041 3DUnet:045:logMetrics E55 trn_all  0.0808 loss,  50.3% tp,  49.7% fn,    1181.2% fp\n",
            "2023-02-04 06:57:12,656 INFO     pid:15041 3DUnet:002:<module> Epoch 56 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:57:12,658 WARNING  pid:15041 util.util:219:enumerateWithEstimate E56 Training ----/23, starting\n",
            "2023-02-04 06:57:29,657 INFO     pid:15041 util.util:236:enumerateWithEstimate E56 Training    4/23, done at 2023-02-04 06:58:26, 0:01:06\n",
            "2023-02-04 06:57:42,547 INFO     pid:15041 util.util:236:enumerateWithEstimate E56 Training    8/23, done at 2023-02-04 06:58:27, 0:01:07\n",
            "2023-02-04 06:58:08,267 INFO     pid:15041 util.util:236:enumerateWithEstimate E56 Training   16/23, done at 2023-02-04 06:58:27, 0:01:07\n",
            "2023-02-04 06:58:26,015 WARNING  pid:15041 util.util:249:enumerateWithEstimate E56 Training ----/23, done at 2023-02-04 06:58:26\n",
            "2023-02-04 06:58:26,018 INFO     pid:15041 3DUnet:004:logMetrics E56 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:58:26,023 INFO     pid:15041 3DUnet:035:logMetrics E56 trn      0.0864 loss, 0.0401 precision, 0.5031 recall, 0.0743 f1 score\n",
            "2023-02-04 06:58:26,028 INFO     pid:15041 3DUnet:045:logMetrics E56 trn_all  0.0864 loss,  50.3% tp,  49.7% fn,    1203.6% fp\n",
            "2023-02-04 06:58:26,034 INFO     pid:15041 3DUnet:002:<module> Epoch 57 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:58:26,037 WARNING  pid:15041 util.util:219:enumerateWithEstimate E57 Training ----/23, starting\n",
            "2023-02-04 06:58:43,149 INFO     pid:15041 util.util:236:enumerateWithEstimate E57 Training    4/23, done at 2023-02-04 06:59:40, 0:01:06\n",
            "2023-02-04 06:58:55,996 INFO     pid:15041 util.util:236:enumerateWithEstimate E57 Training    8/23, done at 2023-02-04 06:59:40, 0:01:07\n",
            "2023-02-04 06:59:21,554 INFO     pid:15041 util.util:236:enumerateWithEstimate E57 Training   16/23, done at 2023-02-04 06:59:40, 0:01:07\n",
            "2023-02-04 06:59:39,342 WARNING  pid:15041 util.util:249:enumerateWithEstimate E57 Training ----/23, done at 2023-02-04 06:59:39\n",
            "2023-02-04 06:59:39,346 INFO     pid:15041 3DUnet:004:logMetrics E57 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 06:59:39,350 INFO     pid:15041 3DUnet:035:logMetrics E57 trn      0.1021 loss, 0.0382 precision, 0.5030 recall, 0.0710 f1 score\n",
            "2023-02-04 06:59:39,352 INFO     pid:15041 3DUnet:045:logMetrics E57 trn_all  0.1021 loss,  50.3% tp,  49.7% fn,    1266.4% fp\n",
            "2023-02-04 06:59:39,359 INFO     pid:15041 3DUnet:002:<module> Epoch 58 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 06:59:39,363 WARNING  pid:15041 util.util:219:enumerateWithEstimate E58 Training ----/23, starting\n",
            "2023-02-04 06:59:56,551 INFO     pid:15041 util.util:236:enumerateWithEstimate E58 Training    4/23, done at 2023-02-04 07:00:54, 0:01:07\n",
            "2023-02-04 07:00:09,287 INFO     pid:15041 util.util:236:enumerateWithEstimate E58 Training    8/23, done at 2023-02-04 07:00:54, 0:01:07\n",
            "2023-02-04 07:00:34,871 INFO     pid:15041 util.util:236:enumerateWithEstimate E58 Training   16/23, done at 2023-02-04 07:00:54, 0:01:07\n",
            "2023-02-04 07:00:52,541 WARNING  pid:15041 util.util:249:enumerateWithEstimate E58 Training ----/23, done at 2023-02-04 07:00:52\n",
            "2023-02-04 07:00:52,544 INFO     pid:15041 3DUnet:004:logMetrics E58 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:00:52,550 INFO     pid:15041 3DUnet:035:logMetrics E58 trn      0.0801 loss, 0.0385 precision, 0.5031 recall, 0.0715 f1 score\n",
            "2023-02-04 07:00:52,555 INFO     pid:15041 3DUnet:045:logMetrics E58 trn_all  0.0801 loss,  50.3% tp,  49.7% fn,    1257.7% fp\n",
            "2023-02-04 07:00:52,558 INFO     pid:15041 3DUnet:002:<module> Epoch 59 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:00:52,564 WARNING  pid:15041 util.util:219:enumerateWithEstimate E59 Training ----/23, starting\n",
            "2023-02-04 07:01:09,716 INFO     pid:15041 util.util:236:enumerateWithEstimate E59 Training    4/23, done at 2023-02-04 07:02:06, 0:01:06\n",
            "2023-02-04 07:01:22,521 INFO     pid:15041 util.util:236:enumerateWithEstimate E59 Training    8/23, done at 2023-02-04 07:02:07, 0:01:06\n",
            "2023-02-04 07:01:48,017 INFO     pid:15041 util.util:236:enumerateWithEstimate E59 Training   16/23, done at 2023-02-04 07:02:07, 0:01:06\n",
            "2023-02-04 07:02:05,895 WARNING  pid:15041 util.util:249:enumerateWithEstimate E59 Training ----/23, done at 2023-02-04 07:02:05\n",
            "2023-02-04 07:02:05,897 INFO     pid:15041 3DUnet:004:logMetrics E59 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:02:05,903 INFO     pid:15041 3DUnet:035:logMetrics E59 trn      0.0732 loss, 0.0405 precision, 0.5029 recall, 0.0749 f1 score\n",
            "2023-02-04 07:02:05,905 INFO     pid:15041 3DUnet:045:logMetrics E59 trn_all  0.0732 loss,  50.3% tp,  49.7% fn,    1192.2% fp\n",
            "2023-02-04 07:02:05,911 INFO     pid:15041 3DUnet:002:<module> Epoch 60 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:02:05,913 WARNING  pid:15041 util.util:219:enumerateWithEstimate E60 Training ----/23, starting\n",
            "2023-02-04 07:02:22,968 INFO     pid:15041 util.util:236:enumerateWithEstimate E60 Training    4/23, done at 2023-02-04 07:03:20, 0:01:06\n",
            "2023-02-04 07:02:35,691 INFO     pid:15041 util.util:236:enumerateWithEstimate E60 Training    8/23, done at 2023-02-04 07:03:20, 0:01:06\n",
            "2023-02-04 07:03:01,166 INFO     pid:15041 util.util:236:enumerateWithEstimate E60 Training   16/23, done at 2023-02-04 07:03:20, 0:01:06\n",
            "2023-02-04 07:03:18,958 WARNING  pid:15041 util.util:249:enumerateWithEstimate E60 Training ----/23, done at 2023-02-04 07:03:18\n",
            "2023-02-04 07:03:18,965 INFO     pid:15041 3DUnet:004:logMetrics E60 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:03:18,966 INFO     pid:15041 3DUnet:035:logMetrics E60 trn      0.0742 loss, 0.0394 precision, 0.5031 recall, 0.0730 f1 score\n",
            "2023-02-04 07:03:18,974 INFO     pid:15041 3DUnet:045:logMetrics E60 trn_all  0.0742 loss,  50.3% tp,  49.7% fn,    1227.5% fp\n",
            "2023-02-04 07:03:18,979 WARNING  pid:15041 util.util:219:enumerateWithEstimate E60 Validation  ----/3, starting\n",
            "2023-02-04 07:03:19,418 WARNING  pid:15041 util.util:249:enumerateWithEstimate E60 Validation  ----/3, done at 2023-02-04 07:03:19\n",
            "2023-02-04 07:03:21,411 INFO     pid:15041 3DUnet:004:logMetrics E60 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:03:21,413 INFO     pid:15041 3DUnet:035:logMetrics E60 val      0.1265 loss, 0.0235 precision, 0.5028 recall, 0.0449 f1 score\n",
            "2023-02-04 07:03:21,416 INFO     pid:15041 3DUnet:045:logMetrics E60 val_all  0.1265 loss,  50.3% tp,  49.7% fn,    2088.2% fp\n",
            "2023-02-04 07:03:22,081 INFO     pid:15041 3DUnet:026:saveModel Model was saved to /gdrive/MyDrive/LiTS_sample/models/bonemeta_fn_0_3D_Unet_DropRes_lv5_All128_model_epoch60\n",
            "2023-02-04 07:03:22,600 INFO     pid:15041 3DUnet:032:saveModel SHA1: b8095d5dfba641761f18895b709c8804b1419391\n",
            "2023-02-04 07:03:22,603 INFO     pid:15041 3DUnet:002:<module> Epoch 61 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:03:22,606 WARNING  pid:15041 util.util:219:enumerateWithEstimate E61 Training ----/23, starting\n",
            "2023-02-04 07:03:39,729 INFO     pid:15041 util.util:236:enumerateWithEstimate E61 Training    4/23, done at 2023-02-04 07:04:36, 0:01:06\n",
            "2023-02-04 07:03:52,584 INFO     pid:15041 util.util:236:enumerateWithEstimate E61 Training    8/23, done at 2023-02-04 07:04:37, 0:01:07\n",
            "2023-02-04 07:04:18,175 INFO     pid:15041 util.util:236:enumerateWithEstimate E61 Training   16/23, done at 2023-02-04 07:04:37, 0:01:07\n",
            "2023-02-04 07:04:35,981 WARNING  pid:15041 util.util:249:enumerateWithEstimate E61 Training ----/23, done at 2023-02-04 07:04:35\n",
            "2023-02-04 07:04:35,987 INFO     pid:15041 3DUnet:004:logMetrics E61 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:04:35,990 INFO     pid:15041 3DUnet:035:logMetrics E61 trn      0.0775 loss, 0.0411 precision, 0.5031 recall, 0.0760 f1 score\n",
            "2023-02-04 07:04:35,992 INFO     pid:15041 3DUnet:045:logMetrics E61 trn_all  0.0775 loss,  50.3% tp,  49.7% fn,    1173.8% fp\n",
            "2023-02-04 07:04:35,996 INFO     pid:15041 3DUnet:002:<module> Epoch 62 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:04:35,998 WARNING  pid:15041 util.util:219:enumerateWithEstimate E62 Training ----/23, starting\n",
            "2023-02-04 07:04:53,024 INFO     pid:15041 util.util:236:enumerateWithEstimate E62 Training    4/23, done at 2023-02-04 07:05:49, 0:01:06\n",
            "2023-02-04 07:05:05,811 INFO     pid:15041 util.util:236:enumerateWithEstimate E62 Training    8/23, done at 2023-02-04 07:05:50, 0:01:06\n",
            "2023-02-04 07:05:31,277 INFO     pid:15041 util.util:236:enumerateWithEstimate E62 Training   16/23, done at 2023-02-04 07:05:50, 0:01:06\n",
            "2023-02-04 07:05:49,029 WARNING  pid:15041 util.util:249:enumerateWithEstimate E62 Training ----/23, done at 2023-02-04 07:05:49\n",
            "2023-02-04 07:05:49,032 INFO     pid:15041 3DUnet:004:logMetrics E62 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:05:49,034 INFO     pid:15041 3DUnet:035:logMetrics E62 trn      0.0746 loss, 0.0385 precision, 0.5031 recall, 0.0715 f1 score\n",
            "2023-02-04 07:05:49,036 INFO     pid:15041 3DUnet:045:logMetrics E62 trn_all  0.0746 loss,  50.3% tp,  49.7% fn,    1257.1% fp\n",
            "2023-02-04 07:05:49,038 INFO     pid:15041 3DUnet:002:<module> Epoch 63 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:05:49,040 WARNING  pid:15041 util.util:219:enumerateWithEstimate E63 Training ----/23, starting\n",
            "2023-02-04 07:06:06,230 INFO     pid:15041 util.util:236:enumerateWithEstimate E63 Training    4/23, done at 2023-02-04 07:07:03, 0:01:07\n",
            "2023-02-04 07:06:19,028 INFO     pid:15041 util.util:236:enumerateWithEstimate E63 Training    8/23, done at 2023-02-04 07:07:03, 0:01:07\n",
            "2023-02-04 07:06:44,623 INFO     pid:15041 util.util:236:enumerateWithEstimate E63 Training   16/23, done at 2023-02-04 07:07:03, 0:01:07\n",
            "2023-02-04 07:07:02,454 WARNING  pid:15041 util.util:249:enumerateWithEstimate E63 Training ----/23, done at 2023-02-04 07:07:02\n",
            "2023-02-04 07:07:02,455 INFO     pid:15041 3DUnet:004:logMetrics E63 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:07:02,460 INFO     pid:15041 3DUnet:035:logMetrics E63 trn      0.0757 loss, 0.0365 precision, 0.5031 recall, 0.0680 f1 score\n",
            "2023-02-04 07:07:02,462 INFO     pid:15041 3DUnet:045:logMetrics E63 trn_all  0.0757 loss,  50.3% tp,  49.7% fn,    1328.8% fp\n",
            "2023-02-04 07:07:02,468 INFO     pid:15041 3DUnet:002:<module> Epoch 64 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:07:02,470 WARNING  pid:15041 util.util:219:enumerateWithEstimate E64 Training ----/23, starting\n",
            "2023-02-04 07:07:19,673 INFO     pid:15041 util.util:236:enumerateWithEstimate E64 Training    4/23, done at 2023-02-04 07:08:16, 0:01:06\n",
            "2023-02-04 07:07:32,346 INFO     pid:15041 util.util:236:enumerateWithEstimate E64 Training    8/23, done at 2023-02-04 07:08:16, 0:01:06\n",
            "2023-02-04 07:07:57,994 INFO     pid:15041 util.util:236:enumerateWithEstimate E64 Training   16/23, done at 2023-02-04 07:08:17, 0:01:07\n",
            "2023-02-04 07:08:15,798 WARNING  pid:15041 util.util:249:enumerateWithEstimate E64 Training ----/23, done at 2023-02-04 07:08:15\n",
            "2023-02-04 07:08:15,800 INFO     pid:15041 3DUnet:004:logMetrics E64 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:08:15,806 INFO     pid:15041 3DUnet:035:logMetrics E64 trn      0.0762 loss, 0.0391 precision, 0.5026 recall, 0.0725 f1 score\n",
            "2023-02-04 07:08:15,808 INFO     pid:15041 3DUnet:045:logMetrics E64 trn_all  0.0762 loss,  50.3% tp,  49.7% fn,    1236.0% fp\n",
            "2023-02-04 07:08:15,811 INFO     pid:15041 3DUnet:002:<module> Epoch 65 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:08:15,815 WARNING  pid:15041 util.util:219:enumerateWithEstimate E65 Training ----/23, starting\n",
            "2023-02-04 07:08:32,950 INFO     pid:15041 util.util:236:enumerateWithEstimate E65 Training    4/23, done at 2023-02-04 07:09:30, 0:01:06\n",
            "2023-02-04 07:08:45,638 INFO     pid:15041 util.util:236:enumerateWithEstimate E65 Training    8/23, done at 2023-02-04 07:09:30, 0:01:06\n",
            "2023-02-04 07:09:11,088 INFO     pid:15041 util.util:236:enumerateWithEstimate E65 Training   16/23, done at 2023-02-04 07:09:30, 0:01:06\n",
            "2023-02-04 07:09:28,869 WARNING  pid:15041 util.util:249:enumerateWithEstimate E65 Training ----/23, done at 2023-02-04 07:09:28\n",
            "2023-02-04 07:09:28,873 INFO     pid:15041 3DUnet:004:logMetrics E65 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:09:28,876 INFO     pid:15041 3DUnet:035:logMetrics E65 trn      0.0795 loss, 0.0405 precision, 0.5029 recall, 0.0750 f1 score\n",
            "2023-02-04 07:09:28,877 INFO     pid:15041 3DUnet:045:logMetrics E65 trn_all  0.0795 loss,  50.3% tp,  49.7% fn,    1191.5% fp\n",
            "2023-02-04 07:09:28,880 INFO     pid:15041 3DUnet:002:<module> Epoch 66 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:09:28,882 WARNING  pid:15041 util.util:219:enumerateWithEstimate E66 Training ----/23, starting\n",
            "2023-02-04 07:09:45,906 INFO     pid:15041 util.util:236:enumerateWithEstimate E66 Training    4/23, done at 2023-02-04 07:10:43, 0:01:06\n",
            "2023-02-04 07:09:58,628 INFO     pid:15041 util.util:236:enumerateWithEstimate E66 Training    8/23, done at 2023-02-04 07:10:43, 0:01:06\n",
            "2023-02-04 07:10:24,142 INFO     pid:15041 util.util:236:enumerateWithEstimate E66 Training   16/23, done at 2023-02-04 07:10:43, 0:01:06\n",
            "2023-02-04 07:10:41,966 WARNING  pid:15041 util.util:249:enumerateWithEstimate E66 Training ----/23, done at 2023-02-04 07:10:41\n",
            "2023-02-04 07:10:41,967 INFO     pid:15041 3DUnet:004:logMetrics E66 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:10:41,974 INFO     pid:15041 3DUnet:035:logMetrics E66 trn      0.0858 loss, 0.0380 precision, 0.5030 recall, 0.0707 f1 score\n",
            "2023-02-04 07:10:41,975 INFO     pid:15041 3DUnet:045:logMetrics E66 trn_all  0.0858 loss,  50.3% tp,  49.7% fn,    1272.1% fp\n",
            "2023-02-04 07:10:41,980 INFO     pid:15041 3DUnet:002:<module> Epoch 67 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:10:41,982 WARNING  pid:15041 util.util:219:enumerateWithEstimate E67 Training ----/23, starting\n",
            "2023-02-04 07:10:59,098 INFO     pid:15041 util.util:236:enumerateWithEstimate E67 Training    4/23, done at 2023-02-04 07:11:56, 0:01:07\n",
            "2023-02-04 07:11:11,841 INFO     pid:15041 util.util:236:enumerateWithEstimate E67 Training    8/23, done at 2023-02-04 07:11:56, 0:01:07\n",
            "2023-02-04 07:11:37,586 INFO     pid:15041 util.util:236:enumerateWithEstimate E67 Training   16/23, done at 2023-02-04 07:11:56, 0:01:07\n",
            "2023-02-04 07:11:55,257 WARNING  pid:15041 util.util:249:enumerateWithEstimate E67 Training ----/23, done at 2023-02-04 07:11:55\n",
            "2023-02-04 07:11:55,263 INFO     pid:15041 3DUnet:004:logMetrics E67 Unet bonemeta_fn_0_3D_Unet_DropRes_lv5_All128\n",
            "2023-02-04 07:11:55,265 INFO     pid:15041 3DUnet:035:logMetrics E67 trn      0.0746 loss, 0.0390 precision, 0.5031 recall, 0.0723 f1 score\n",
            "2023-02-04 07:11:55,267 INFO     pid:15041 3DUnet:045:logMetrics E67 trn_all  0.0746 loss,  50.3% tp,  49.7% fn,    1240.9% fp\n",
            "2023-02-04 07:11:55,269 INFO     pid:15041 3DUnet:002:<module> Epoch 68 of 200, 23/3 batches of size 2*1\n",
            "2023-02-04 07:11:55,271 WARNING  pid:15041 util.util:219:enumerateWithEstimate E68 Training ----/23, starting\n",
            "2023-02-04 07:12:12,472 INFO     pid:15041 util.util:236:enumerateWithEstimate E68 Training    4/23, done at 2023-02-04 07:13:10, 0:01:07\n",
            "2023-02-04 07:12:25,353 INFO     pid:15041 util.util:236:enumerateWithEstimate E68 Training    8/23, done at 2023-02-04 07:13:10, 0:01:07\n",
            "2023-02-04 07:12:50,975 INFO     pid:15041 util.util:236:enumerateWithEstimate E68 Training   16/23, done at 2023-02-04 07:13:10, 0:01:07\n"
          ]
        }
      ],
      "source": [
        "for epoch_ndx in range(1, EPOCHS+1):\n",
        "    log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
        "        epoch_ndx,\n",
        "        EPOCHS,\n",
        "        len(train_dl),\n",
        "        len(val_dl),\n",
        "        BATCH_SIZE,\n",
        "        (torch.cuda.device_count() if USE_CUDA else 1),\n",
        "    ))\n",
        "\n",
        "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
        "\n",
        "    logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
        "\n",
        "    if epoch_ndx == 1 or epoch_ndx % validation_cadence == 0:\n",
        "        # if validation is wanted\n",
        "        valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
        "        score = logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
        "        best_score = max(score, best_score)\n",
        "\n",
        "        # self.saveModel('seg', epoch_ndx, score == best_score)\n",
        "        saveModel('seg', epoch_ndx)\n",
        "        # self.logImages(epoch_ndx, 'trn', train_dl)\n",
        "        # self.logImages(epoch_ndx, 'val', val_dl)\n",
        "        \n",
        "trn_writer.close()\n",
        "val_writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB5Zd_kn8bes",
        "outputId": "ef387e03-fc9d-4803-ec21-91aa4b6f33ec",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_3in3out_trn_seg_2022-08-02_01.36.14\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_3in3out_val_seg_2022-08-02_01.36.14\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_trn_seg_2022-05-04_01.38.21\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_trn_seg_2022-05-04_03.39.03\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_trn_seg_2022-05-04_07.15.44\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_trn_seg_2022-09-04_16.43.26\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_val_seg_2022-05-04_01.38.21\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_val_seg_2022-05-04_03.39.03\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_val_seg_2022-05-04_07.15.44\r\n",
            "bonemeta_fn_0_3D_Unet_DropRes_lv6_All128_val_seg_2022-09-04_16.43.26\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv5_All128_trn_seg_2022-04-21_15.19.04\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv5_All128_val_seg_2022-04-21_15.19.04\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv6_All128_trn_seg_2022-04-28_21.47.09\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv6_All128_trn_seg_2022-04-29_08.34.58\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv6_All128_trn_seg_2022-04-29_16.23.54\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv6_All128_trn_seg_2022-04-29_22.03.37\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv6_All128_val_seg_2022-04-28_21.47.09\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv6_All128_val_seg_2022-04-29_08.34.58\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv6_All128_val_seg_2022-04-29_16.23.54\r\n",
            "bonemeta_fn_0_3D_Unet_Res_lv6_All128_val_seg_2022-04-29_22.03.37\r\n",
            "bonemeta_fn_1_3D_Unet_DropRes_lv6_All128_trn_seg_2022-05-03_12.04.54\r\n",
            "bonemeta_fn_1_3D_Unet_DropRes_lv6_All128_val_seg_2022-05-03_12.04.54\r\n"
          ]
        }
      ],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /gdrive/MyDrive/LiTS_sample/logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ULtPupsnmpQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "BoneSegmentation_window_1300300_FN0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}